{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"2D_CNN_residual_demo.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"MrnpPGYoE-St"},"source":["# Import library"]},{"cell_type":"code","metadata":{"id":"uZU5VGv9FFHG","outputId":"aa3e00a9-11cc-4ad5-e248-d0d384dd2972","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","4/1AfDhmrh6yjrRAOYL36wIoH14ei6QNXHjKIWyYE2kOLjnENYtIRMQYn2z2lM\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fUAAiX1bFVMV","executionInfo":{"status":"ok","timestamp":1604042116079,"user_tz":-480,"elapsed":674,"user":{"displayName":"F94056152羅翊芳","photoUrl":"","userId":"14159951463955383384"}},"outputId":"0bb1cb8d-09dd-4988-aa32-ba6cbce84fdc","colab":{"base_uri":"https://localhost:8080/"}},"source":["! nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fri Oct 30 07:15:15 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   51C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"VdEDakjNE-Su","executionInfo":{"status":"ok","timestamp":1604042121270,"user_tz":-480,"elapsed":2465,"user":{"displayName":"F94056152羅翊芳","photoUrl":"","userId":"14159951463955383384"}},"outputId":"efbb549b-a80f-4e6d-88b5-aa3ef7cba705","colab":{"base_uri":"https://localhost:8080/"}},"source":["import os\n","import time\n","import random\n","import pickle\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","from matplotlib import pyplot as plt\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","print(\"tf version:\", tf.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tf version: 2.3.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cPoipRSSE-Sy"},"source":["# Set random seed"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"F-JJwmigE-Sy"},"source":["os.environ['PYTHONHASHSEED']=str(1)\n","os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # new flag present in tf 2.0+\n","random.seed(1)\n","np.random.seed(1)\n","tf.random.set_seed(1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6tRNWPgEE-S1"},"source":["# Limit GPU resource"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"Q2jYkQloE-S2","executionInfo":{"status":"ok","timestamp":1604042131440,"user_tz":-480,"elapsed":5989,"user":{"displayName":"F94056152羅翊芳","photoUrl":"","userId":"14159951463955383384"}},"outputId":"37961bb5-5be2-4193-8e36-387d320f2f63","colab":{"base_uri":"https://localhost:8080/"}},"source":["gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","  try:\n","    # Currently, memory growth needs to be the same across GPUs\n","    for gpu in gpus:\n","      tf.config.experimental.set_memory_growth(gpu, True)\n","    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","  except RuntimeError as e:\n","    # Memory growth must be set before GPUs have been initialized\n","    print(e)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1 Physical GPUs, 1 Logical GPUs\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oX4lJBfpE-S5"},"source":["# Plot acc and loss figure"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"cFcoiNTrE-S6"},"source":["def plot_acc(train_history):\n","    \"\"\"\n","    This function is used for plot accuracy curve\n","    during training process\n","    Parameters\n","    -----------\n","    train_history : variables names of training process\n","    \"\"\"\n","    plt.plot(history.history['accuracy'])\n","    plt.plot(history.history['val_accuracy'])\n","    plt.title('Train History')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy')\n","    plt.legend(['train', 'validation'], loc = 'upper left')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"1UVkZ-lEE-S9"},"source":["def plot_loss(train_history):\n","    \"\"\"\n","    This function is used for plot loss figure\n","    during training process\n","    Parameters\n","    -----------\n","    train_history : variables names of training process\n","    \"\"\"\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title('Train History')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend(['train', 'validation'], loc = 'upper left')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"07gmmJ6HE-TA"},"source":["# plot confusion matrix"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"r_6U-M8nE-TA"},"source":["def plot_confusion_matrix(cm, classes,\n","                          normalize = False,\n","                          title = 'Confusion matrix',\n","                          cmap = plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \n","    Parameter\n","    ---------\n","    cm : confusion matrix\n","    classes : various category\n","    normalize : True, False\n","    title : you can type anthing you in it, but the data type must be \"string\"\n","    default 'Confusion matrix'\n","    cmap : default 'plt.cm.Blues'\n","    reference : https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            plt.text(j, i, format(cm[i, j], fmt),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    plt.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X9GEpu1PE-TD"},"source":["# One hot encoder to label encoder"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"y25qbj8BE-TF"},"source":["def onehot_to_label(data):\n","    \"\"\"\n","    This function is used for transform one hot encoding\n","    to label encoding\n","    \n","    Paramenters\n","    -----------\n","    data : array-like of shape (n_samples, n_category)\n","    \n","    Returns\n","    -------\n","    label encoder\n","    \"\"\"\n","    label = []\n","    for i in range(len(data)):\n","        for j in range(len(data[i])):\n","            if data[i][j] == 1:\n","                label.append(j)\n","    return label"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N4uQ5bBGE-TI"},"source":["# Load data intra subject"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"Y64xOEYoE-TI"},"source":["def load_data(time, condition):\n","    \n","    \"\"\"\n","    This function is used for load pickle file\n","    from same folder\n","    \n","    Parameters\n","    ----------\n","    time : '2s', '1s', '0.5s'\n","    condition : 'stationary', 'holding'\n","    \n","    Returns\n","    -------\n","    data : tensor-like of shape (number_of_samples, time_length, 8, 8)\n","    label : label of each category\n","    \"\"\"\n","    \n","    \n","    labels = []\n","    gesture_type = 1\n","    gestures = ['pat', 'stroke', 'grab', 'poke', 'scratch', 'notouch']\n","    pickle_path = '/content/drive/My Drive/研究資料(共用)/pickle/' + condition + ' test'\n","    if time == '2s':\n","        data = np.zeros((1,120, 8, 8))\n","    elif time == '1s':\n","        data = np.zeros((1,60, 8, 8))\n","    else:\n","        data = np.zeros((1,30, 8, 8))\n","    \n","    if condition == 'stationary':\n","        for gesture in gestures:\n","            file_name = 'raw_data_' + gesture + '_' + time + '_s1s25_s.pck1'\n","            pickle_file = open(os.path.join(pickle_path, file_name), 'rb')\n","            array = pickle.load(pickle_file)\n","            pickle_file.close()\n","            data = np.concatenate((data, array))\n","            label = [gesture_type for i in range(len(array))]\n","            labels = np.concatenate((labels, label))\n","            gesture_type += 1\n","    else:\n","        for gesture in gestures:\n","            file_name = 'raw_data_' + gesture + '_' + time + '_s1s25_h.pck1'\n","            pickle_file = open(os.path.join(pickle_path, file_name), 'rb')\n","            array = pickle.load(pickle_file)\n","            pickle_file.close()\n","            data = np.concatenate((data, array))\n","            label = [gesture_type for i in range(len(array))]\n","            labels = np.concatenate((labels, label))\n","            gesture_type += 1\n","\n","    o_label = np.array(pd.get_dummies(labels))\n","    data = data[1:]\n","    data = data.astype('float32')\n","    return data, o_label"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5nlpW9sbE-TL"},"source":["# load data inter subject"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"KnmlMHVmE-TL"},"source":["def load_random_subject(time, condition_1, condition_2, folder):\n","    \"\"\"\n","    This function is used for load pickle file\n","    from various folder\n","    \n","    Parameters\n","    ----------\n","    time : '2s', '1s', '0.5s'\n","    condition_1 : 'stationary', 'holding'\n","    condition_2 : 'train', 'test'\n","    folder : 1, 2, 3, ...10\n","    \n","    Returns\n","    -------\n","    data : tensor-like of shape (number_of_samples, time_length, 8, 8)\n","    label : label of each category\n","    \"\"\"\n","    labels = []\n","    gestures = ['pat', 'stroke', 'grab', 'poke', 'scratch', 'notouch']\n","    gesture_type = 1\n","    pickle_path = '/content/drive/My Drive/研究資料(共用)/different subject train test/' + condition_1 + '_s1s25' + '/cv_' + str(folder)\n","    if time == '2s':\n","        data = np.zeros((1,120, 8, 8))\n","    elif time == '1s':\n","        data = np.zeros((1,60, 8, 8))\n","    else:\n","        data = np.zeros((1,30, 8, 8))\n","    \n","    if condition_1 == 'stationary':\n","        for gesture in gestures:\n","            file_name = 'raw_data_' + condition_2 + '_' + gesture + '_' + time + '_s1s25_s_cv_' + str(folder) + '.pck1'\n","            pickle_file = open(os.path.join(pickle_path, file_name), 'rb')\n","            array = pickle.load(pickle_file)\n","            pickle_file.close()\n","            data = np.concatenate((data, array))\n","            label = [gesture_type for i in range(len(array))]\n","            labels = np.concatenate((labels, label))\n","            gesture_type += 1\n","    else:\n","        for gesture in gestures:\n","            file_name = 'raw_data_' + condition_2 + '_' + gesture + '_' + time + '_s1s25_h_cv_' + str(folder) + '.pck1'\n","            pickle_file = open(os.path.join(pickle_path, file_name), 'rb')\n","            array = pickle.load(pickle_file)\n","            pickle_file.close()\n","            data = np.concatenate((data, array))\n","            label = [gesture_type for i in range(len(array))]\n","            labels = np.concatenate((labels, label))\n","            gesture_type += 1\n","               \n","    o_label = np.array(pd.get_dummies(labels))\n","    data = data[1:]\n","    data = data.astype('float32')\n","    return data, o_label"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eeBy0GyeE-TO"},"source":["# Random select data"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"zvXVi_wJE-TP"},"source":["def random_select(s_data, s_olabel, h_data, h_olabel):\n","    \"\"\"\n","    This function can shuffle the data\n","    \n","    Parameter\n","    ---------\n","    s_data: data from stationary dataset\n","    s_olabel : label from stationary dataset\n","    h_data: data from holding dataset\n","    h_olabel : label from holding dataset\n","    \n","    Returns\n","    -------\n","    half of numbers of each posture dataset\n","    \"\"\"\n","    len_s = len(s_olabel)\n","    len_h = len(h_olabel)\n","    s_randomize = np.arange(len_s)\n","    h_randomize = np.arange(len_h)\n","    np.random.shuffle(s_randomize)\n","    np.random.shuffle(h_randomize)\n","    half_s_data = s_data[s_randomize[:int(0.5 * len_s)]]\n","    half_h_data = h_data[h_randomize[:int(0.5 * len_h)]]\n","    half_s_olabel = s_olabel[s_randomize[:int(0.5 * len_s)]]\n","    half_h_olabel = h_olabel[h_randomize[:int(0.5 * len_h)]]\n","    \n","    return half_s_data, half_s_olabel, half_h_data, half_h_olabel"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FFiOwnvmE-TR"},"source":["# Identity Block"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"ILLuIdmrE-TR"},"source":["def identity_block(X, f, filters):\n","    \"\"\"\n","    This function is used for build the fundamental residual block\n","    \n","    Parameter\n","    ---------\n","    X : input data\n","    f : filter size\n","    filters: numbers of filters\n","    \n","    Returns\n","    -------\n","    tensor-like shape\n","    \"\"\"\n","    # Retrive Filters\n","    f1, f2, f3 = filters\n","    # Save input value\n","    x_shortcut = X\n","    \n","    # first component of main path\n","    \n","    x = tf.keras.layers.Conv2D(f1, kernel_size = 1, padding = 'same', kernel_initializer = 'he_uniform',\n","                              data_format = 'channels_first')(X)\n","    x = tf.keras.layers.BatchNormalization(axis = 1)(x)\n","    x = tf.keras.activations.swish(x)\n","    \n","    # second component of main path\n","    \n","    x = tf.keras.layers.Conv2D(f2, kernel_size = f, padding = 'same', kernel_initializer = 'he_uniform',\n","                              data_format = 'channels_first')(x)\n","    x = tf.keras.layers.BatchNormalization(axis = 1)(x)\n","    x = tf.keras.activations.swish(x)\n","    \n","    # Third component of main path\n","    \n","    x = tf.keras.layers.Conv2D(f3, kernel_size = 1, padding = 'same', kernel_initializer = 'he_uniform',\n","                              data_format = 'channels_first')(x)\n","    x = tf.keras.layers.BatchNormalization(axis = 1)(x)\n","    \n","    # Final step: Add shortcut value to main path, and pass it through a Swish activation\n","    x = tf.keras.layers.add([x, x_shortcut])\n","    x = tf.keras.activations.swish(x)\n","    \n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JLnP4LvrE-TU"},"source":["# 2D CNN with BatchNormalization"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"77CQ9nKfE-TU"},"source":["def cnn2d_bn(x, f, size):\n","    \"\"\"\n","    This function is used for build the fundamental convolutional block\n","    \n","    Parameter\n","    ---------\n","    X : input data\n","    size : filter size\n","    filters: numbers of filters\n","    \n","    Returns\n","    -------\n","    tensor-like shape\n","    \"\"\"\n","    \n","    cnn2d = tf.keras.layers.Conv2D(f, kernel_size = size, padding = 'same',\n","                                  kernel_initializer = 'he_uniform',\n","                                  data_format = 'channels_first')(x)\n","    \n","    bn = tf.keras.layers.BatchNormalization(axis = 1)(cnn2d)\n","    \n","    act = tf.keras.activations.swish(bn)\n","    \n","    return act"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mrsuWWdfE-TY"},"source":["# Model"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"bZ9wzKA7E-TY"},"source":["def cnn_2d(input_shape, learning_rate):\n","    \"\"\"\n","    This function is used for build the model\n","    \n","    Parameter\n","    ---------\n","    input_shape : define the input shape\n","    learning_rate : define learning rate which was set in optimizer\n","    \n","    Returns\n","    -------\n","    whole model\n","    \"\"\"\n","    \n","    input_data = tf.keras.Input(shape = input_shape, name = 'input_data_shape')\n","    \n","    x = cnn2d_bn(input_data, 32, 1)\n","    \n","    x = identity_block(x, (3, 3), [8, 8, 32])\n","    \n","    x = tf.keras.layers.MaxPool2D(pool_size = (2, 2), data_format = 'channels_first')(x)\n","    \n","    x = identity_block(x, (3, 3), [16, 16, 32])\n","    \n","    x = cnn2d_bn(x, 64, 1)\n","    \n","    x = tf.keras.layers.GlobalAveragePooling2D(data_format = 'channels_first')(x)\n","    \n","    output = tf.keras.layers.Dense(6, activation = 'softmax')(x)\n","    \n","    model = tf.keras.Model(inputs = input_data, outputs = output)\n","    \n","    ranger = tfa.optimizers.Lookahead(tfa.optimizers.RectifiedAdam(lr = learning_rate, warmup_proportion = 0.1), \n","                                      sync_period = 6, slow_step_size = 0.6)\n","    model.compile(optimizer = ranger, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"sR8ZJWjVE-Tb"},"source":["cnn_2d((120, 8, 8)).summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZfJaE06mE-Td"},"source":["# intra subject (same posture)"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"wG1m6fl3E-Te","executionInfo":{"status":"error","timestamp":1604042298280,"user_tz":-480,"elapsed":858,"user":{"displayName":"F94056152羅翊芳","photoUrl":"","userId":"14159951463955383384"}},"outputId":"5f38b152-ba34-4242-d8cd-59b93159ba2c","colab":{"base_uri":"https://localhost:8080/","height":437}},"source":["# Theses list can be iterated throgh for loop\n","#--------------------------------------------------------------------------------\n","times = ['2s','1s','0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","phase = ['stationary', 'holding']\n","#--------------------------------------------------------------------------------\n","# this part is to define input data shape and load data\n","#--------------------------------------------------------------------------------\n","for c in phase:\n","    conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","    for length in times:\n","        i = 1\n","        cvscores = []\n","        print('Now start 10 fold cross validation')\n","        print('phase = ' + c)\n","        print('data_length = ' + length)\n","        print('Now, start for ' + length)\n","        if length == '2s' :\n","            input_shape = (120, 8, 8)\n","        elif length == '1s':\n","            input_shape = (60, 8, 8)\n","        else:\n","            input_shape = (30, 8, 8)\n","        data, o_label = load_data(length, c)\n","        label = onehot_to_label(o_label)\n","        label = np.reshape(label, (len(label), 1))\n","        k_fold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1)\n","#--------------------------------------------------------------------------------\n","# this part is to perform 10-fold cross validation\n","#--------------------------------------------------------------------------------\n","        for train, validate in k_fold.split(data, label):\n","            print('Now, start the cv: ',i)\n","            x_train, y_train = data[train], label[train]\n","            x_validate, y_validate = data[validate], label[validate]\n","            y_train = tf.keras.utils.to_categorical(y_train, num_classes = 6)\n","            y_val = tf.keras.utils.to_categorical(y_validate, num_classes = 6)\n","            model = cnn_2d(input_shape = input_shape, learning_rate = 1e-3)\n","            history = model.fit(x_train, y_train, epochs = 35, batch_size = 32, verbose = 2, shuffle = True,\n","                               validation_data = (x_validate, y_val))\n","            pred = np.argmax(model.predict(x_validate), axis = 1)\n","            real_label = onehot_to_label(y_val)\n","            scores = accuracy_score(real_label, pred)* 100\n","            print(\"The accuracy in this fold: %f\"%scores)\n","            print(\"=============================\")\n","            cvscores.append(scores)\n","            conf_mat = np.expand_dims(confusion_matrix(y_validate, pred), axis = 2)\n","            conf_mat_all = np.concatenate([conf_mat_all, conf_mat], axis = 2)\n","            i += 1\n","#--------------------------------------------------------------------------------\n","# this part is to plot acc,loss curve and print out the average accuracy\n","#--------------------------------------------------------------------------------    \n","            # plot_acc(history)\n","            # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/acc and loss/' + '2D_CNN' + '_' + c + '_' + length + '_intra subject accuracy.png')\n","            # plt.show()\n","            # plot_loss(history)\n","            # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/acc and loss/' + '2D_CNN' + '_' + c + '_' + length + '_intra subject loss.png')\n","            # plt.show()\n","        print(length + \" Total Accuracy (average): \", np.mean(cvscores), np.std(cvscores))\n","        print(\"=============================================\")\n","        print(\"=============================================\")\n","#--------------------------------------------------------------------------------\n","# this part i to plot confusion matrix\n","#--------------------------------------------------------------------------------        \n","    conf_mat_sum = np.sum(conf_mat_all, axis = 2)\n","    plot_confusion_matrix(conf_mat_sum, classes = gestures, cmap = plt.cm.Blues,\n","                      normalize = True)\n","    # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/confusion matrix/' + '2D_CNN' + '_' + c + '_intra subject confusion_matrix.png')\n","    plt.show()\n","#--------------------------------------------------------------------------------"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Now start 10 fold cross validation\n","phase = stationary\n","data_length = 2s\n","Now, start for 2s\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-a0cb0a9571c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot_to_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-01f79df918d0>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(time, condition)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgesture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgestures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'raw_data_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgesture\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_s1s25_s.pck1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mpickle_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mpickle_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/研究資料(共用)/pickle/stationary test/raw_data_pat_2s_s1s25_s.pck1'"]}]},{"cell_type":"markdown","metadata":{"id":"GWVcO3e8E-Tg"},"source":["# intra subject (different posture)"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"jinOYUe4E-Th"},"source":["# These list can be iterated throgh for loop\n","times = ['2s', '1s', '0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","#--------------------------------------------------------------------------------\n","# this part is to define input data shape and confusion matrix, then load data\n","#--------------------------------------------------------------------------------\n","conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","for length in times:\n","    cvscores = []\n","    print('Now, start for ' + length)\n","    if length == '2s' :\n","        input_shape = (120, 8, 8)\n","    elif length == '1s':\n","        input_shape = (60, 8, 8)\n","    else:\n","        input_shape = (30, 8, 8)    \n","    s_data, s_o_label = load_data(length, 'stationary')\n","    h_data, h_o_label = load_data(length, 'holding')\n","#--------------------------------------------------------------------------------\n","# this part is to perform 10-fold cross validation\n","#--------------------------------------------------------------------------------\n","    for i in range(1, 11):\n","        print('Now, start the cv: ',i)\n","        x_s_train, x_s_test, y_s_train, y_s_test = train_test_split(s_data, s_o_label, test_size = 0.1, shuffle = True)\n","        x_h_train, x_h_test, y_h_train, y_h_test = train_test_split(h_data, h_o_label, test_size = 0.1, shuffle = True)\n","        model = cnn_2d(input_shape = input_shape, learning_rate = 1e-3)\n","        history = model.fit(x_h_train, y_h_train, epochs = 20, batch_size = 32, verbose = 0,\n","                            shuffle = True, validation_data = (x_s_test, y_s_test))\n","        pred = np.argmax(model.predict(x_s_test), axis = 1)\n","        real_label = onehot_to_label(y_s_test)\n","        scores = accuracy_score(real_label, pred) * 100\n","        print('The accuracy in this fold is: %f'%scores)\n","        conf_mat = np.expand_dims(confusion_matrix(real_label, pred), axis = 2)\n","        conf_mat_all = np.concatenate([conf_mat, conf_mat_all], axis = 2)\n","#--------------------------------------------------------------------------------\n","# this part is to plot acc and loss curve and print out the average accuracy\n","#--------------------------------------------------------------------------------   \n","        # plot_acc(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/acc and loss/' + '2D_CNN' + '_' + length + '_intra subject train_holding_test_stationary accuracy.png')\n","        # plt.show()\n","        # plot_loss(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/acc and loss/' + '2D_CNN' + '_' + length + '_intra subject train_holding_test_stationary loss.png')\n","        # plt.show()\n","        cvscores.append(scores)\n","    print(length + \" Total Accuracy (average): \", np.mean(cvscores), np.std(cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\")\n","#--------------------------------------------------------------------------------\n","# this part is to plot confusion matrix\n","#--------------------------------------------------------------------------------\n","conf_mat_sum = np.sum(conf_mat_all, axis = 2)\n","plot_confusion_matrix(conf_mat_sum, classes = gestures, cmap = plt.cm.Blues, normalize = True)\n","# plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/confusion matrix/' + '2D_CNN_' + '_train_holding_test_stationary confusion_matrix.png')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"6EVieHKCE-Tj"},"source":["# These list can be iterated throgh for loop\n","times = ['2s', '1s', '0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","#--------------------------------------------------------------------------------\n","# this part is to define input data shape and confusion matrix, then load data\n","#--------------------------------------------------------------------------------\n","conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","for length in times:\n","    cvscores = []\n","    print('Now, start for ' + length)\n","    if length == '2s' :\n","        input_shape = (120, 8, 8)\n","    elif length == '1s':\n","        input_shape = (60, 8, 8)\n","    else:\n","        input_shape = (30, 8, 8)    \n","    s_data, s_o_label = load_data(length, 'stationary')\n","    h_data, h_o_label = load_data(length, 'holding')\n","#--------------------------------------------------------------------------------\n","# this part is to perform 10-fold cross validation\n","#--------------------------------------------------------------------------------\n","    for i in range(1, 11):\n","        print('Now, start the cv: ',i)\n","        x_s_train, x_s_test, y_s_train, y_s_test = train_test_split(s_data, s_o_label, test_size = 0.1, shuffle = True)\n","        x_h_train, x_h_test, y_h_train, y_h_test = train_test_split(h_data, h_o_label, test_size = 0.1, shuffle = True)\n","        model = cnn_2d(input_shape = input_shape, learning_rate = 1e-3)\n","        history = model.fit(x_s_train, y_s_train, epochs = 20, batch_size = 32, verbose = 2,\n","                            shuffle = True, validation_data = (x_h_test, y_h_test))\n","        pred = np.argmax(model.predict(x_h_test), axis = 1)\n","        real_label = onehot_to_label(y_h_test)\n","        scores = accuracy_score(real_label, pred) * 100\n","        print('The accuracy is this fold is : %f'%scores)\n","        cvscores.append(scores)\n","        conf_mat = np.expand_dims(confusion_matrix(real_label, pred), axis = 2)\n","        conf_mat_all = np.concatenate([conf_mat, conf_mat_all], axis = 2)\n","#--------------------------------------------------------------------------------\n","# this part is to plot acc, loss curve and print out the average accuracy\n","#--------------------------------------------------------------------------------\n","        # plot_acc(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/acc and loss/' + '2D_CNN' + '_' + length + '_intra subject train_stationary_test_holding accuracy.png')\n","        # plt.show()\n","        # plot_loss(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/acc and loss/' + '2D_CNN' + '_' + length + '_intra subject train_stationary_test_holding loss.png')\n","        # plt.show()\n","    print(length + \" Total Accuracy (average): \", np.mean(cvscores), np.std(cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\")\n","#--------------------------------------------------------------------------------\n","# this part is to plot confusion matrix\n","#--------------------------------------------------------------------------------\n","conf_mat_sum = np.sum(conf_mat_all, axis = 2)\n","plot_confusion_matrix(conf_mat_sum, classes = gestures, cmap = plt.cm.Blues, normalize = True)\n","# plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/confusion matrix/' + '2D_CNN_' + '_train_stationary_test_holding confusion_matrix.png')\n","plt.show()\n","#--------------------------------------------------------------------------------"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s7FTkGkhE-Tl"},"source":["# Inter subject (same posture)"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"ZSOeQKRRE-Tm"},"source":["# These list can be iterated throgh for loop\n","times = ['2s','1s','0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","#--------------------------------------------------------------------------------\n","# this part is to define input data shape and confusion matrix\n","#--------------------------------------------------------------------------------\n","conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","for length in times:\n","    cvscores = []\n","    print('Now, start for ' + length)\n","    if length == '2s' :\n","        input_shape = (120, 8, 8)\n","    elif length == '1s':\n","        input_shape = (60, 8, 8)\n","    else:\n","        input_shape = (30, 8, 8)\n","#--------------------------------------------------------------------------------\n","# this part is to load data and perform 10-fold cross validation\n","#--------------------------------------------------------------------------------     \n","    for i in range(1,11):\n","        train_data, train_olabel = load_random_subject(length, 'stationary', 'train', i)\n","        test_data, test_olabel = load_random_subject(length, 'stationary', 'test', i) \n","        print('Now, start the cv: ',i)\n","        model = cnn_2d(input_shape = input_shape, learning_rate = 1e-3)\n","        history = model.fit(train_data,train_olabel,epochs = 20, batch_size = 32,verbose = 2,shuffle = True,\n","                          validation_data = (test_data,test_olabel))\n","        pred = np.argmax(model.predict(test_data), axis = 1)\n","        real_label = onehot_to_label(test_olabel)\n","        scores = accuracy_score(real_label, pred) * 100\n","        print(\"The accuracy in this fold: %f\"%scores)\n","        print(\"=============================\")\n","        cvscores.append(scores)\n","        conf_mat = np.expand_dims(confusion_matrix(real_label, pred), axis = 2)\n","        conf_mat_all = np.concatenate([conf_mat_all, conf_mat], axis = 2)\n","#--------------------------------------------------------------------------------\n","# this part is to plot acc, loss curve and print out the average accuracy\n","#--------------------------------------------------------------------------------\n","        # plot_acc(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/acc and loss/' + '2D_CNN' + '_' + length + '_inter subject (stationary) accuracy.png')\n","        # plt.show()\n","        # plot_loss(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/acc and loss/' + '2D_CNN' + '_' + length + '_inter subject (stationary) loss.png')\n","        # plt.show()\n","    print(length + \" Total Accuracy (average): \", np.mean(cvscores), np.std(cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\")\n","#--------------------------------------------------------------------------------\n","# this part is to plot confusion matrix\n","#--------------------------------------------------------------------------------    \n","conf_mat_sum = np.sum(conf_mat_all, axis = 2)\n","plot_confusion_matrix(conf_mat_sum, classes = gestures, cmap = plt.cm.Blues,\n","                  normalize = True)\n","# plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/confusion matrix/' + '2D_CNN' + ' stationary '+ ' inter_subject confusion_matrix.png')\n","plt.show()\n","#--------------------------------------------------------------------------------"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"BF83ywc6E-To"},"source":["# These list can be iterated throgh for loop\n","times = ['2s','1s','0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","#--------------------------------------------------------------------------------\n","# this part is to define input data shape and confusion matrix\n","#--------------------------------------------------------------------------------\n","for length in times:\n","    cvscores = []\n","    print('Now, start for ' + length)\n","    if length == '2s' :\n","        input_shape = (120, 8, 8)\n","    elif length == '1s':\n","        input_shape = (60, 8, 8)\n","    else:\n","        input_shape = (30, 8, 8)\n","#--------------------------------------------------------------------------------\n","# this part is to load data and perform 10-fold cross validation\n","#-------------------------------------------------------------------------------- \n","    for i in range(1,11):\n","        train_data, train_olabel = load_random_subject(length, 'holding', 'train', i)\n","        test_data, test_olabel = load_random_subject(length, 'holding', 'test', i) \n","        print('Now, start the cv: ',i)\n","        model = cnn_2d(input_shape = input_shape, learning_rate = 1e-3)\n","        history = model.fit(train_data,train_olabel,epochs = 20, batch_size = 32,verbose = 2,shuffle = True,\n","                          validation_data=(test_data,test_olabel))\n","        pred = np.argmax(model.predict(test_data), axis = 1)\n","        real_label = onehot_to_label(test_olabel)\n","        scores = accuracy_score(real_label, pred) * 100\n","        print(\"The accuracy in this fold: %f\"%scores)\n","        print(\"=============================\")\n","        cvscores.append(scores)\n","        conf_mat = np.expand_dims(confusion_matrix(real_label, pred), axis = 2)\n","        conf_mat_all = np.concatenate([conf_mat_all, conf_mat], axis = 2)\n","#--------------------------------------------------------------------------------\n","# this part is to plot acc, loss curve and print out the average accuracy\n","#--------------------------------------------------------------------------------\n","        # plot_acc(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/acc and loss/' + '2D_CNN' + '_' + length + '_inter subject (holding) accuracy.png')\n","        # plt.show()\n","        # plot_loss(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/acc and loss/' + '2D_CNN' + '_' + length + '_inter subject (holding) loss.png')\n","        # plt.show()\n","    print(length + \" Total Accuracy (average): \", np.mean(cvscores), np.std(cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\")\n","#--------------------------------------------------------------------------------\n","# this part is to plot confusion matrix\n","# -------------------------------------------------------------------------------   \n","conf_mat_sum = np.sum(conf_mat_all, axis = 2)\n","plot_confusion_matrix(conf_mat_sum, classes = gestures, cmap = plt.cm.Blues,\n","                  normalize = True)\n","# plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/confusion matrix/' + '2D_CNN' + ' holding '+ ' inter_subject(holding) confusion_matrix.png')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bzY2hpEWE-Tr"},"source":["# Inter subject (different posture)"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"cjmq1FetE-Tr"},"source":["# These list can be iterated throgh for loop\n","times = ['2s','1s','0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","# -------------------------------------------------------------------------------\n","# this part is to define input data shape and confusion matrix\n","# -------------------------------------------------------------------------------\n","for length in times:\n","    cvscores = []\n","    print('Now, start for ' + length)\n","    if length == '2s' :\n","        input_shape = (120, 8, 8)\n","    elif length == '1s':\n","        input_shape = (60, 8, 8)\n","    else:\n","        input_shape = (30, 8, 8)\n","# -------------------------------------------------------------------------------\n","# this part is to load data and perform 10-fold cross validation\n","# -------------------------------------------------------------------------------       \n","    for i in range(1,11):\n","        train_data, train_olabel = load_random_subject(length, 'stationary', 'train', i)\n","        test_data, test_olabel = load_random_subject(length, 'holding', 'test', i) \n","        print('Now, start the cv: ',i)\n","        model = cnn_2d(input_shape = input_shape, learning_rate = 1e-3)\n","        history = model.fit(train_data,train_olabel,epochs = 20, batch_size = 32,verbose = 2,shuffle = True,\n","                          validation_data=(test_data,test_olabel))\n","        pred = np.argmax(model.predict(test_data), axis = 1)\n","        real_label = onehot_to_label(test_olabel)\n","        scores = accuracy_score(real_label, pred) * 100\n","        print(\"The accuracy in this fold: %f\"%scores)\n","        print(\"=============================\")\n","        cvscores.append(scores)\n","        conf_mat = np.expand_dims(confusion_matrix(real_label, pred), axis = 2)\n","        conf_mat_all = np.concatenate([conf_mat_all, conf_mat], axis = 2)\n","# -------------------------------------------------------------------------------\n","# this part is to plot acc, loss curve and print out the average accuracy\n","# -------------------------------------------------------------------------------\n","        # plot_acc(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/acc and loss/' + '2D_CNN' + '_' + length + '_inter subject (train stationary test holding) accuracy.png')\n","        # plt.show()\n","        # plot_loss(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/acc and loss/' + '2D_CNN' + '_' + length + '_inter subject (train stationary test holding) loss.png')\n","        # plt.show()\n","    print(length + \" Total Accuracy (average): \", np.mean(cvscores), np.std(cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\")\n","# -------------------------------------------------------------------------------\n","# this part is to plot confusion matrix\n","# -------------------------------------------------------------------------------   \n","conf_mat_sum = np.sum(conf_mat_all, axis = 2)\n","plot_confusion_matrix(conf_mat_sum, classes = gestures, cmap = plt.cm.Blues,\n","                  normalize = True)\n","# plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/confusion matrix/' + '2D_CNN' + ' (train stationary test holding) '+ ' inter_subject confusion_matrix.png')\n","plt.show()\n","# -------------------------------------------------------------------------------"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"R04uNKosE-Tu"},"source":["# Theses list can be iterated throgh for loop\n","#-------------------------------------------------------------------------------\n","times = ['2s','1s','0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","#-------------------------------------------------------------------------------\n","# this part is to define input data shape and confusion matrix\n","#-------------------------------------------------------------------------------\n","conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","for length in times:\n","    cvscores = []\n","    print('Now, start for ' + length)\n","    if length == '2s' :\n","        input_shape = (120, 8, 8)\n","    elif length == '1s':\n","        input_shape = (60, 8, 8)\n","    else:\n","        input_shape = (30, 8, 8)\n","#-------------------------------------------------------------------------------\n","# this part is to load data and perform 10-fold cross validation\n","#-------------------------------------------------------------------------------\n","    for i in range(1,11):\n","        train_data, train_olabel = load_random_subject(length, 'holding', 'train', i)\n","        test_data, test_olabel = load_random_subject(length, 'stationary', 'test', i) \n","        print('Now, start the cv: ',i)\n","        model = cnn_2d(input_shape = input_shape, learning_rate = 1e-3)\n","        history = model.fit(train_data,train_olabel,epochs = 20, batch_size = 32,verbose = 2,shuffle = True,\n","                          validation_data=(test_data,test_olabel))\n","        pred = np.argmax(model.predict(test_data), axis = 1)\n","        real_label = onehot_to_label(test_olabel)\n","        scores = accuracy_score(real_label, pred) * 100\n","        print(\"The accuracy in this fold: %f\"%scores)\n","        print(\"=============================\")\n","        cvscores.append(scores)\n","        conf_mat = np.expand_dims(confusion_matrix(real_label, pred), axis = 2)\n","        conf_mat_all = np.concatenate([conf_mat_all, conf_mat], axis = 2)\n","#-------------------------------------------------------------------------------\n","# this part is to plot acc, loss curve and print out the average accuracy\n","#-------------------------------------------------------------------------------\n","        # plot_acc(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/acc and loss/' + '2D_CNN' + '_' + length + '_inter subject (train holding test stationary.png')\n","        # plt.show()\n","        # plot_acc(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/acc and loss/' + '2D_CNN' + '_' + length + '_inter subject (train holding test stationary) loss.png')\n","        # plt.show()\n","    print(length + \" Total Accuracy (average): \", np.mean(cvscores), np.std(cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\")\n","#-------------------------------------------------------------------------------\n","# this part is to plot confusion matrix\n","#-------------------------------------------------------------------------------       \n","conf_mat_sum = np.sum(conf_mat_all, axis = 2)\n","plot_confusion_matrix(conf_mat_sum, classes = gestures, cmap = plt.cm.Blues,\n","                  normalize = True)\n","# plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/confusion matrix/' + '2D_CNN' + ' (train holding test stationary) '+ ' inter_subject confusion_matrix.png')\n","plt.show()\n","# -------------------------------------------------------------------------------"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mM5_5QNHE-Tx"},"source":["# Inter Subject (Combine)"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"gVdHT3X_E-Tx"},"source":["# Theses list can be iterated throgh for loop\n","# -------------------------------------------------------------------------------\n","times = ['2s', '1s', '0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","# -------------------------------------------------------------------------------\n","# this part is to define input data shap and confusion matrix\n","# -------------------------------------------------------------------------------\n","s_conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","for length in times:\n","    s_cvscores = []\n","    print('Now, start for ' + length)\n","    if length == '2s' :\n","        input_shape = (120, 8, 8)\n","    elif length == '1s':\n","        input_shape = (60, 8, 8)\n","    else:\n","        input_shape = (30, 8, 8)\n","# -------------------------------------------------------------------------------\n","# this part is to load data and perform 10-fold cross validation\n","# -------------------------------------------------------------------------------\n","    for i in range(1,11):\n","        s_train_data, s_train_olabel = load_random_subject(length, 'stationary', 'train',  i)\n","        h_train_data, h_train_olabel = load_random_subject(length, 'holding', 'train', i)\n","        half_s_train_data, half_s_train_olabel, half_h_train_data, half_h_train_olabel = random_select(s_train_data, s_train_olabel, h_train_data, h_train_olabel)\n","        t_train_data = np.concatenate((half_s_train_data, half_h_train_data))\n","        t_train_olabel = np.concatenate((half_s_train_olabel, half_h_train_olabel))\n","        s_test_data, s_test_olabel = load_random_subject(length, 'stationary', 'test', i)\n","        print('Now, start the cv: ',i)\n","        model = cnn_2d(input_shape = input_shape, learning_rate = 1e-3)\n","        history = model.fit(t_train_data,t_train_olabel,epochs = 20, batch_size = 32,verbose = 2, shuffle = True,\n","                            validation_data = (s_test_data, s_test_olabel))\n","        s_pred = np.argmax(model.predict(s_test_data), axis = 1)\n","        s_real_label = onehot_to_label(s_test_olabel)\n","        s_scores = accuracy_score(s_real_label, s_pred) * 100\n","        print(\"The accuracy in this fold (test stationary): %f\"%s_scores)\n","        print(\"=============================\")\n","        s_cvscores.append(s_scores)\n","        s_conf_mat = np.expand_dims(confusion_matrix(s_real_label, s_pred), axis = 2)\n","        s_conf_mat_all = np.concatenate([s_conf_mat_all, s_conf_mat], axis = 2)\n","# -------------------------------------------------------------------------------\n","# this part is to plot acc, loss curve and print out the average accuracy\n","# -------------------------------------------------------------------------------  \n","        # plot_acc(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/acc and loss/' + '2D_CNN' + '_' + length + '_inter subject (combine test stationary).png')\n","        # plt.show()\n","        # plot_loss(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/acc and loss/' + '2D_CNN' + '_' + length + '_inter subject (combine test stationary) loss.png')\n","        # plt.show()\n","    print('Test : stationary')\n","    print(length + \" Total Accuracy (average): \", np.mean(s_cvscores), np.std(s_cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\") \n","# -------------------------------------------------------------------------------\n","# this part is to plot confusion matrix\n","# -------------------------------------------------------------------------------   \n","s_conf_mat_sum = np.sum(s_conf_mat_all, axis = 2)\n","plot_confusion_matrix(s_conf_mat_sum, classes = gestures, cmap = plt.cm.Blues,\n","                  normalize = True)\n","# plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/confusion matrix/' + '2D_CNN' + ' combine_half_test_stationary ' + ' inter_subject confusion_matrix.png')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"cTdufGnQE-T0"},"source":["# Theses list can be iterated throgh for loop\n","#------------------------------------------------------------\n","times = ['2s', '1s', '0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","h_conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","#------------------------------------------------------------------------\n","# this part is to define input data shape and confusion matrix\n","# ----------------------------------------------------------------------\n","for length in times:\n","    h_cvscores = []\n","    print('Now, start for ' + length)\n","    if length == '2s' :\n","        input_shape = (120, 8, 8)\n","    elif length == '1s':\n","        input_shape = (60, 8, 8)\n","    else:\n","        input_shape = (30, 8, 8)\n","# -------------------------------------------------------------------------------\n","# this part is to load data and perform 10-fold cross validation\n","#--------------------------------------------------------------------------------         \n","    for i in range(1,11):\n","        s_train_data, s_train_olabel = load_random_subject(length, 'stationary', 'train',  i)\n","        h_train_data, h_train_olabel = load_random_subject(length, 'holding', 'train', i)\n","        half_s_train_data, half_s_train_olabel, half_h_train_data, half_h_train_olabel = random_select(s_train_data, s_train_olabel, h_train_data, h_train_olabel)\n","        t_train_data = np.concatenate((half_s_train_data, half_h_train_data))\n","        t_train_olabel = np.concatenate((half_s_train_olabel, half_h_train_olabel))\n","        h_test_data, h_test_olabel = load_random_subject(length, 'holding', 'test', i)\n","        print('Now, start the cv: ',i)\n","        model = cnn_2d(input_shape = input_shape, learning_rate = 1e-3)\n","        history = model.fit(t_train_data,t_train_olabel,epochs = 20, batch_size = 32,verbose = 2, shuffle = True,\n","                            validation_data = (h_test_data, h_test_olabel))\n","        h_pred = np.argmax(model.predict(h_test_data), axis = 1)\n","        h_real_label = onehot_to_label(h_test_olabel)\n","        h_scores = accuracy_score(h_real_label, h_pred) * 100\n","        print('The accuracy in this fold (test holding): %f'%h_scores)\n","        print(\"=============================\")\n","        h_cvscores.append(h_scores)\n","        h_conf_mat = np.expand_dims(confusion_matrix(h_real_label, h_pred), axis = 2)\n","        h_conf_mat_all = np.concatenate([h_conf_mat_all, h_conf_mat], axis = 2)\n","# -------------------------------------------------------------------------------\n","# this part is to plot acc, loss curve and print out the average accuracy\n","# ------------------------------------------------------------------------------- \n","        # plot_acc(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/acc and loss/' + '2D_CNN' + '_' + length + '_inter subject (combine test holding).png')\n","        # plt.show()\n","        # plot_loss(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/acc and loss/' + '2D_CNN' + '_' + length + '_inter subject (combine test holding) loss.png')\n","        # plt.show()\n","    print('Test : holding')\n","    print(length + \" Total Accuracy (average): \", np.mean(h_cvscores), np.std(h_cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\")\n","# -------------------------------------------------------------------------------\n","# this part is to plot confusion matrix\n","# -------------------------------------------------------------------------------\n","h_conf_mat_sum = np.sum(h_conf_mat_all, axis = 2)\n","plot_confusion_matrix(h_conf_mat_sum, classes = gestures, cmap = plt.cm.Blues,\n","                  normalize = True)\n","# plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/confusion matrix/' + '2D_CNN' + ' combine_half_test_holding ' + ' inter_subject confusion_matrix.png')\n","plt.show()"],"execution_count":null,"outputs":[]}]}