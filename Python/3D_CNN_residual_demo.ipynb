{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"name":"3D_CNN_residual_demo.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2xsFeItXHICG"},"source":["# Import library"]},{"cell_type":"code","metadata":{"id":"HBElx8o6OAgX","executionInfo":{"status":"ok","timestamp":1603939100836,"user_tz":-480,"elapsed":19338,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}},"outputId":"79c179de-d4a5-4774-d884-3697a58762d5","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"gi_S3hZlHICI","executionInfo":{"status":"ok","timestamp":1603938967789,"user_tz":-480,"elapsed":2425,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}},"outputId":"e83d45ff-ad92-491f-abd5-2407d0d9fcea","colab":{"base_uri":"https://localhost:8080/"}},"source":["import os\n","import random\n","import pickle\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","from matplotlib import pyplot as plt\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","print(\"tf version:\", tf.__version__)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["tf version: 2.3.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Qzm6Hp2OHICT"},"source":["# Set random seed"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"h3KYNngcHICU","executionInfo":{"status":"ok","timestamp":1603938970481,"user_tz":-480,"elapsed":702,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}}},"source":["os.environ['PYTHONHASHSEED'] = str(1)\n","os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # new flag present in tf 2.0+\n","random.seed(1)\n","np.random.seed(1)\n","tf.random.set_seed(1)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g_0l7SE2HICW"},"source":["# Limit GPU resource"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"i6CuS0DRHICX","outputId":"69febaf4-7b6d-4c10-a733-25e1723d139a"},"source":["gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","  try:\n","    # Currently, memory growth needs to be the same across GPUs\n","    for gpu in gpus:\n","      tf.config.experimental.set_memory_growth(gpu, True)\n","    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","  except RuntimeError as e:\n","    # Memory growth must be set before GPUs have been initialized\n","    print(e)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1 Physical GPUs, 1 Logical GPUs\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aPEGHNuAHICZ"},"source":["# Plot acc and loss figure"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"E6HgYidZHICa","executionInfo":{"status":"ok","timestamp":1603939054588,"user_tz":-480,"elapsed":630,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}}},"source":["def plot_acc(train_history):\n","    \"\"\"\n","    This function is used for plot acc curve\n","    during training process\n","    Parameters\n","    -----------\n","    train_history : variables names of training process\n","    \"\"\"\n","    plt.plot(history.history['accuracy'])\n","    plt.plot(history.history['val_accuracy'])\n","    plt.title('Train History')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy')\n","    plt.legend(['train', 'validation'], loc = 'upper left')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"t8nSxUjzHICc","executionInfo":{"status":"ok","timestamp":1603939056610,"user_tz":-480,"elapsed":643,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}}},"source":["def plot_loss(train_history):\n","    \"\"\"\n","    This function is used for plot loss curve\n","    Parameters\n","    -----------\n","    train_history : variables names of training process\n","    \"\"\"\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title('Train History')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend(['train', 'validation'], loc = 'upper left')"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"myOW6PsQHICg"},"source":["# plot confusion matrix"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"Xr6S78t1HICg","executionInfo":{"status":"ok","timestamp":1603939058699,"user_tz":-480,"elapsed":614,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}}},"source":["def plot_confusion_matrix(cm, classes,\n","                          normalize = False,\n","                          title = 'Confusion matrix',\n","                          cmap = plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \n","    Parameter\n","    ---------\n","    cm : confusion matrix\n","    classes : various category\n","    normalize : True, False\n","    title : you can type anthing you in it, but the data type must be \"string\"\n","    default 'Confusion matrix'\n","    cmap : default 'plt.cm.Blues'\n","    reference : https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n","    else:\n","        print('Confusion matrix, without normalization')\n","    \n","    plt.imshow(cm, interpolation = 'nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            plt.text(j, i, format(cm[i, j], fmt),\n","                     horizontalalignment = \"center\",\n","                     color = \"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    plt.tight_layout()"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zBLTr5sKHICj"},"source":["# One hot encoder to label encoder"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"rNKDPw45HICk","executionInfo":{"status":"ok","timestamp":1603939061226,"user_tz":-480,"elapsed":734,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}}},"source":["def onehot_to_label(data):\n","    \"\"\"\n","    This function is used for transform one hot encoding\n","    to label encoding\n","    \n","    Parameters\n","    -----------\n","    data : array-like of shape (n_samples, n_category)\n","    \n","    Returns\n","    -------\n","    label encoder\n","    \"\"\"   \n","    label = []\n","    for i in range(len(data)):\n","        for j in range(len(data[i])):\n","            if data[i][j] == 1:\n","                label.append(j)\n","    return label"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QNKiMHKSHICn"},"source":["# Load data"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"4AouFa-7HICn","executionInfo":{"status":"ok","timestamp":1603939064390,"user_tz":-480,"elapsed":797,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}}},"source":["def load_data(time, condition):\n","    \"\"\"\n","    This function is used for load pickle\n","    from same folder\n","    \n","    Parameters\n","    ----------\n","    time : '2s', '1s', '0.5s'\n","    condition_1 : 'stationary', 'holding'\n","    condition_2 : 'train', 'test'\n","    folder : 1, 2, 3, ...10\n","    \n","    Returns\n","    -------\n","    data : tensor-like of shape (number_of_samples, 1, time_length, 8, 8)\n","    label : label of each category\n","    \"\"\"\n","    labels = []\n","    gesture_type = 1\n","    gestures = ['pat', 'stroke', 'grab', 'poke', 'scratch', 'notouch']\n","    pickle_path = '/content/drive/My Drive/研究資料(共用)/pickle/' + condition + ' test'\n","    if time == '2s':\n","        data = np.zeros((1,120, 8, 8))\n","    elif time == '1s':\n","        data = np.zeros((1,60, 8, 8))\n","    else:\n","        data = np.zeros((1,30, 8, 8))\n","    \n","    if condition == 'stationary':\n","        for gesture in gestures:\n","            file_name = 'raw_data_' + gesture + '_' + time + '_s1s25_s.pck1'\n","            pickle_file = open(os.path.join(pickle_path, file_name), 'rb')\n","            array = pickle.load(pickle_file)\n","            pickle_file.close()\n","            data = np.concatenate((data, array))\n","            label = [gesture_type for i in range(len(array))]\n","            labels = np.concatenate((labels, label))\n","            gesture_type += 1\n","    else:\n","        for gesture in gestures:\n","            file_name = 'raw_data_' + gesture + '_' + time + '_s1s25_h.pck1'\n","            pickle_file = open(os.path.join(pickle_path, file_name), 'rb')\n","            array = pickle.load(pickle_file)\n","            pickle_file.close()\n","            data = np.concatenate((data, array))\n","            label = [gesture_type for i in range(len(array))]\n","            labels = np.concatenate((labels, label))\n","            gesture_type += 1\n","            \n","    if time == '2s':\n","        data_3d = np.reshape(data,(len(data),1,120,8,8))\n","    elif time == '1s':\n","        data_3d = np.reshape(data,(len(data),1,60,8,8))\n","    else:\n","        data_3d = np.reshape(data,(len(data),1,30,8,8))\n","\n","    o_label = np.array(pd.get_dummies(labels))\n","    data_3d = data_3d[1:]\n","    data_3d = data_3d.astype('float32')\n","    return data_3d, o_label"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s3PMfA96HICp"},"source":["# load data inter subject"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"WP4S4TvuHICq","executionInfo":{"status":"ok","timestamp":1603939325850,"user_tz":-480,"elapsed":857,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}}},"source":["def load_random_subject(time, condition_1, condition_2, folder):\n","    \"\"\"\n","    This function is used for load data\n","    from various folder\n","    \n","    Parameters\n","    ----------\n","    time : '2s', '1s', '0.5s'\n","    condition_1 : 'stationary', 'holding'\n","    condition_2 : 'train', 'test'\n","    folder : 1, 2, 3, ...10\n","    \n","    Returns\n","    -------\n","    data : tensor-like of shape (number_of_samples, 1, time_length, 8, 8)\n","    label : label of each category\n","    \"\"\"\n","    labels = []\n","    gestures = ['pat', 'stroke', 'grab', 'poke', 'scratch', 'notouch']\n","    gesture_type = 1\n","    pickle_path = '/content/drive/My Drive/研究資料(共用)/different subject train test/' + condition_1 + '_s1s25' + '/cv_' + str(folder)\n","    if time == '2s':\n","        data = np.zeros((1,120, 8, 8))\n","    elif time == '1s':\n","        data = np.zeros((1,60, 8, 8))\n","    else:\n","        data = np.zeros((1,30, 8, 8))\n","    \n","    if condition_1 == 'stationary':\n","        for gesture in gestures:\n","            file_name = 'raw_data_' + condition_2 + '_' + gesture + '_' + time + '_s1s25_s_cv_' + str(folder) + '.pck1'\n","            pickle_file = open(os.path.join(pickle_path, file_name), 'rb')\n","            array = pickle.load(pickle_file)\n","            pickle_file.close()\n","            data = np.concatenate((data, array))\n","            label = [gesture_type for i in range(len(array))]\n","            labels = np.concatenate((labels, label))\n","            gesture_type += 1\n","    else:\n","        for gesture in gestures:\n","            file_name = 'raw_data_' + condition_2 + '_' + gesture + '_' + time + '_s1s25_h_cv_' + str(folder) + '.pck1'\n","            pickle_file = open(os.path.join(pickle_path, file_name), 'rb')\n","            array = pickle.load(pickle_file)\n","            pickle_file.close()\n","            data = np.concatenate((data, array))\n","            label = [gesture_type for i in range(len(array))]\n","            labels = np.concatenate((labels, label))\n","            gesture_type += 1\n","            \n","    if time == '2s':\n","        data_3d = np.reshape(data,(len(data),1,120,8,8))\n","    elif time == '1s':\n","        data_3d = np.reshape(data,(len(data),1,60,8,8))\n","    else:\n","        data_3d = np.reshape(data,(len(data),1,30,8,8))\n","        \n","    o_label = np.array(pd.get_dummies(labels))\n","    data_3d = data_3d[1:]\n","    data_3d = data_3d.astype('float32')\n","    return data_3d, o_label"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1TlNCEmjHICs"},"source":["# Random select data"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"_S2-y4epHICs","executionInfo":{"status":"ok","timestamp":1603939110564,"user_tz":-480,"elapsed":598,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}}},"source":["def random_select(s_data, s_olabel, h_data, h_olabel):\n","    \"\"\"\n","    This function can shuffle the data\n","    \n","    Parameter\n","    ---------\n","    s_data: data from stationary dataset\n","    s_olabel : label from stationary dataset\n","    h_data: data from holding dataset\n","    h_olabel : label from holding dataset\n","    \n","    Returns\n","    -------\n","    half of numbers of each posture dataset\n","    \"\"\"\n","    len_s = len(s_olabel)\n","    len_h = len(h_olabel)\n","    s_randomize = np.arange(len_s)\n","    h_randomize = np.arange(len_h)\n","    np.random.shuffle(s_randomize)\n","    np.random.shuffle(h_randomize)\n","    half_s_data = s_data[s_randomize[:int(0.5 * len_s)]]\n","    half_h_data = h_data[h_randomize[:int(0.5 * len_h)]]\n","    half_s_olabel = s_olabel[s_randomize[:int(0.5 * len_s)]]\n","    half_h_olabel = h_olabel[h_randomize[:int(0.5 * len_h)]]\n","    \n","    return half_s_data, half_s_olabel, half_h_data, half_h_olabel"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IMe77b-bHICv"},"source":["# Identity Block"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"K7Q2Cw2tHICw","executionInfo":{"status":"ok","timestamp":1603939112453,"user_tz":-480,"elapsed":598,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}}},"source":["def identity_block(X, f, filters):\n","    \"\"\"\n","    This function is used for build the fundamental residual block\n","    \n","    Parameter\n","    ---------\n","    X : input data\n","    f : filter size\n","    filters: numbers of filters\n","    \n","    Returns\n","    -------\n","    tensor-like shape\n","    \"\"\"    \n","    # Retrive Filters\n","    f1, f2, f3 = filters\n","    # Save input value\n","    x_shortcut = X\n","    \n","    # first component of main path\n","    \n","    x = tf.keras.layers.Conv3D(f1, kernel_size = 1, padding = 'same', kernel_initializer = 'he_uniform',\n","                              data_format = 'channels_first')(X)\n","    x = tf.keras.layers.BatchNormalization(axis = 1)(x)\n","    x = tf.keras.activations.swish(x)\n","    \n","    # second component of main path\n","    \n","    x = tf.keras.layers.Conv3D(f2, kernel_size = f, padding = 'same', kernel_initializer = 'he_uniform',\n","                              data_format = 'channels_first')(x)\n","    x = tf.keras.layers.BatchNormalization(axis = 1)(x)\n","    x = tf.keras.activations.swish(x)\n","    \n","    # Third component of main path\n","    \n","    x = tf.keras.layers.Conv3D(f3, kernel_size = 1, padding = 'same', kernel_initializer = 'he_uniform',\n","                              data_format = 'channels_first')(x)\n","    x = tf.keras.layers.BatchNormalization(axis = 1)(x)\n","    \n","    # Final step: Add shortcut value to main path, and pass it through a Swish activation\n","    x = tf.keras.layers.add([x, x_shortcut])\n","    x = tf.keras.activations.swish(x)\n","    \n","    return x"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b23IhKX1HICz"},"source":["# 3D CNN with BatchNormalization"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"dPH5O3pTHICz","executionInfo":{"status":"ok","timestamp":1603939114733,"user_tz":-480,"elapsed":601,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}}},"source":["def cnn3d_bn(x, f, size):\n","    \"\"\"\n","    This function is used for build the fundamental convolutional block\n","    \n","    Parameter\n","    ---------\n","    X : input data\n","    size : filter size\n","    filters: numbers of filters\n","    \n","    Returns\n","    -------\n","    tensor-like shape\n","    \"\"\"    \n","    cnn3d = tf.keras.layers.Conv3D(f, kernel_size = size, padding = 'same',\n","                                  kernel_initializer = 'he_uniform',\n","                                  data_format = 'channels_first')(x)\n","    \n","    bn = tf.keras.layers.BatchNormalization(axis = 1)(cnn3d)\n","    \n","    act = tf.keras.activations.swish(bn)\n","    \n","    return act"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4DRv_ivOHIC2"},"source":["# Model"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"BFPVo3YBHIC2","executionInfo":{"status":"ok","timestamp":1603939117804,"user_tz":-480,"elapsed":610,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}}},"source":["def cnn_3d(input_shape, learning_rate):\n","    \n","    \"\"\"\n","    This function is used for build the model\n","    \n","    Parameter\n","    ---------\n","    input_shape : define the input shape\n","    learning_rate : define learning rate which was set in optimizer\n","    \n","    Returns\n","    -------\n","    whole model\n","    \"\"\"\n","    \n","    input_data = tf.keras.Input(shape = input_shape, name = 'input_data_shape')\n","    \n","    x = cnn3d_bn(input_data, 32, (1, 3, 3))\n","    \n","    x = identity_block(x, (7, 3, 3), [8, 8, 32])\n","    \n","    x = tf.keras.layers.MaxPool3D(pool_size = (5, 2, 2), data_format = 'channels_first')(x)\n","    \n","    x = identity_block(x, (7, 3, 3), [16, 16, 32])\n","    \n","    x = cnn3d_bn(x, 64, 1)\n","    \n","    x = tf.keras.layers.GlobalAveragePooling3D(data_format = 'channels_first')(x)\n","    \n","    output = tf.keras.layers.Dense(6, activation = 'softmax')(x)\n","    \n","    model = tf.keras.Model(inputs = input_data, outputs = output)\n","    \n","    ranger = tfa.optimizers.Lookahead(tfa.optimizers.RectifiedAdam(lr = learning_rate, warmup_proportion = 0.1), \n","                                      sync_period = 6, slow_step_size = 0.6)\n","\n","    model.compile(optimizer = ranger, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","    \n","    return model"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"PBZ6xMyBHIC4"},"source":["cnn_3d((1, 120, 8, 8)).summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P2XVRTSvHIC7"},"source":["# Intra Subject (same posture)"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"RAi7xmvjHIC7","executionInfo":{"status":"error","timestamp":1603939261276,"user_tz":-480,"elapsed":126787,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}},"outputId":"681b259d-fe33-4cfc-8640-28834e280147","colab":{"base_uri":"https://localhost:8080/","height":670}},"source":["# These list can be iterated throgh for loop\n","#--------------------------------------------------------------------------------\n","times = ['2s','1s','0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","phase = ['stationary', 'holding']\n","#-------------------------------------------------------------------------------- \n","# this part is to define input data shape and load data\n","#-------------------------------------------------------------------------------- \n","for c in phase:\n","    conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","    for length in times:\n","        i = 1\n","        cvscores = []\n","        print('Now start 10 fold cross validation')\n","        print('phase = ' + c)\n","        print('data_length = ' + length)\n","        print('Now, start for ' + length)\n","        \n","        if length == '2s' :\n","            input_shape = (1, 120, 8, 8)\n","        elif length == '1s':\n","            input_shape = (1, 60, 8, 8)\n","        else:\n","            input_shape = (1, 30, 8, 8)\n","            \n","        data, o_label = load_data(length, c)\n","        label = onehot_to_label(o_label)\n","        label = np.reshape(label, (len(label), 1))\n","#-------------------------------------------------------------------------------- \n","# this part is to perform 10-fold cross validation\n","#--------------------------------------------------------------------------------\n","        k_fold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1)\n","        for train, validate in k_fold.split(data, label):\n","            print('Now, start the cv: ',i)\n","            x_train, y_train = data[train], label[train]\n","            x_validate, y_validate = data[validate], label[validate]\n","            y_train = tf.keras.utils.to_categorical(y_train, num_classes = 6)\n","            y_val = tf.keras.utils.to_categorical(y_validate, num_classes = 6)\n","            model = cnn_3d(input_shape = input_shape, learning_rate = 1e-3)\n","            history = model.fit(x_train, y_train, epochs = 15, batch_size = 32, verbose = 2, shuffle = True,\n","                               validation_data = (x_validate, y_val))\n","            pred = np.argmax(model.predict(x_validate), axis = 1)\n","            real_label = onehot_to_label(y_val)\n","            scores = accuracy_score(real_label, pred)* 100\n","            print(\"The accuracy in this fold: %f\"%scores)\n","            print(\"=============================\")\n","            cvscores.append(scores)\n","            conf_mat = np.expand_dims(confusion_matrix(y_validate, pred), axis = 2)\n","            conf_mat_all = np.concatenate([conf_mat_all, conf_mat], axis = 2)\n","            i += 1\n","#--------------------------------------------------------------------------------\n","# this part is to plot acc,loss curve and print out the average accuracy\n","#-------------------------------------------------------------------------------- \n","            # plot_acc(history)\n","            # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/acc and loss/' + '3D_CNN' + '_' + c + '_' + length + '_intra subject accuracy.png')\n","            # plt.show()\n","            # plot_loss(history)\n","            # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/acc and loss/' + '3D_CNN' + '_' + c + '_' + length + '_intra subject loss.png')\n","            # plt.show()\n","        print(length + \" Total Accuracy (average): \", np.mean(cvscores), np.std(cvscores))\n","        print(\"=============================================\")\n","        print(\"=============================================\")\n","#-------------------------------------------------------------------------------- \n","# this part i to plot confusion matrix\n","#--------------------------------------------------------------------------------               \n","    conf_mat_sum = np.sum(conf_mat_all, axis = 2)\n","    plot_confusion_matrix(conf_mat_sum, classes = gestures, cmap = plt.cm.Blues,\n","                      normalize = True)\n","    # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/confusion matrix/' + '3D_CNN' + '_' + c + '_intra subject confusion_matrix.png')\n","    plt.show()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Now start 10 fold cross validation\n","phase = stationary\n","data_length = 2s\n","Now, start for 2s\n","Now, start the cv:  1\n","Epoch 1/15\n","209/209 - 19s - loss: 1.6043 - accuracy: 0.3394 - val_loss: 1.3675 - val_accuracy: 0.4966\n","Epoch 2/15\n","209/209 - 18s - loss: 1.1682 - accuracy: 0.5659 - val_loss: 1.0724 - val_accuracy: 0.6110\n","Epoch 3/15\n","209/209 - 18s - loss: 0.8393 - accuracy: 0.6828 - val_loss: 0.8086 - val_accuracy: 0.6837\n","Epoch 4/15\n","209/209 - 18s - loss: 0.6248 - accuracy: 0.7639 - val_loss: 0.5113 - val_accuracy: 0.8264\n","Epoch 5/15\n","209/209 - 18s - loss: 0.4755 - accuracy: 0.8153 - val_loss: 0.4226 - val_accuracy: 0.8304\n","Epoch 6/15\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-7b64447245c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             history = model.fit(x_train, y_train, epochs = 15, batch_size = 32, verbose = 2, shuffle = True,\n\u001b[0;32m---> 41\u001b[0;31m                                validation_data = (x_validate, y_val))\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_validate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mreal_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot_to_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"PyWlfhLnHIC-"},"source":["# Intra Subject (different posture)"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"u0CCAG3BHIC-"},"source":["# These list can be iterated throgh for loop\n","times = ['2s', '1s', '0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","#-------------------------------------------------------------------------------- \n","# this part is to define input data shape and confusion matrix, then load data\n","#-------------------------------------------------------------------------------- \n","conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","for length in times:\n","    cvscores = []\n","    print('Now, start for ' + length)\n","    if length == '2s' :\n","        input_shape = (1, 120, 8, 8)\n","    elif length == '1s':\n","        input_shape = (1, 60, 8, 8)\n","    else:\n","        input_shape = (1, 30, 8, 8)    \n","    s_data, s_o_label = load_data(length, 'stationary')\n","    h_data, h_o_label = load_data(length, 'holding')\n","#-------------------------------------------------------------------------------- \n","# this part is to perform 10-fold cross validation\n","#--------------------------------------------------------------------------------\n","    for i in range(1, 11):\n","        print('Now, start the cv: ',i)\n","        x_s_train, x_s_test, y_s_train, y_s_test = train_test_split(s_data, s_o_label, test_size = 0.1, shuffle = True)\n","        x_h_train, x_h_test, y_h_train, y_h_test = train_test_split(h_data, h_o_label, test_size = 0.1, shuffle = True)\n","        model = cnn_3d(input_shape = input_shape, learning_rate = 1e-3)\n","        history = model.fit(x_h_train, y_h_train, epochs = 15, batch_size = 32, verbose = 2,\n","                            shuffle = True, validation_data = (x_s_test, y_s_test))\n","        pred = np.argmax(model.predict(x_s_test), axis = 1)\n","        real_label = onehot_to_label(y_s_test)\n","        scores = accuracy_score(real_label, pred) * 100\n","        cvscores.append(scores)\n","        print('The accuracy in this fold is: %f'%scores)\n","        conf_mat = np.expand_dims(confusion_matrix(real_label, pred), axis = 2)\n","        conf_mat_all = np.concatenate([conf_mat, conf_mat_all], axis = 2)\n","#-------------------------------------------------------------------------------- \n","# this part is to plot acc and loss curve and print out the average accuracy\n","#--------------------------------------------------------------------------------  \n","        # plot_acc(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/acc and loss/' + '3D_CNN' + '_' + length + '_intra subject train_holding_test_stationary accuracy.png')\n","        # plt.show()\n","        # plot_loss(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/acc and loss/' + '3D_CNN' + '_' + length + '_intra subject train_holding_test_stationary loss.png')\n","        # plt.show()\n","    print(length + \" Total Accuracy (average): \", np.mean(cvscores), np.std(cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\")\n","#-------------------------------------------------------------------------------- \n","# this part is to plot confusion matrix\n","#-------------------------------------------------------------------------------- \n","conf_mat_sum = np.sum(conf_mat_all, axis = 2)\n","plot_confusion_matrix(conf_mat_sum, classes = gestures, cmap = plt.cm.Blues, normalize = True)\n","# plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/confusion matrix/' + '3D_CNN_' + '_train_holding_test_stationary confusion_matrix.png')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"nPct9rP9HIDC"},"source":["# These list can be iterated throgh for loop\n","times = ['2s', '1s', '0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","#-------------------------------------------------------------------------------- \n","# this part is to define input data shape and confusion matrix, then load data\n","#-------------------------------------------------------------------------------- \n","for length in times:\n","    cvscores = []\n","    print('Now, start for ' + length)\n","    if length == '2s' :\n","        input_shape = (1, 120, 8, 8)\n","    elif length == '1s':\n","        input_shape = (1, 60, 8, 8)\n","    else:\n","        input_shape = (1, 30, 8, 8)    \n","    s_data, s_o_label = load_data(length, 'stationary')\n","    h_data, h_o_label = load_data(length, 'holding')\n","#-------------------------------------------------------------------------------- \n","# this part is to perform 10-fold cross validation\n","#-------------------------------------------------------------------------------- \n","    for i in range(1, 11):\n","        print('Now, start the cv: ',i)\n","        x_s_train, x_s_test, y_s_train, y_s_test = train_test_split(s_data, s_o_label, test_size = 0.1, shuffle = True)\n","        x_h_train, x_h_test, y_h_train, y_h_test = train_test_split(h_data, h_o_label, test_size = 0.1, shuffle = True)\n","        model = cnn_3d(input_shape = input_shape, learning_rate = 1e-3)\n","        history = model.fit(x_s_train, y_s_train, epochs = 15, batch_size = 32, verbose = 2,\n","                            shuffle = True, validation_data = (x_h_test, y_h_test))\n","        pred = np.argmax(model.predict(x_h_test), axis = 1)\n","        real_label = onehot_to_label(y_h_test)\n","        scores = accuracy_score(real_label, pred) * 100\n","        cvscores.append(scores)\n","        print('The accuracy is this fold is : %f'%scores)\n","        conf_mat = np.expand_dims(confusion_matrix(real_label, pred), axis = 2)\n","        conf_mat_all = np.concatenate([conf_mat, conf_mat_all], axis = 2)\n","#-------------------------------------------------------------------------------- \n","# this part is to plot acc, loss figire and print out the average accuracy\n","#-------------------------------------------------------------------------------- \n","        # plot_acc(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/acc and loss/' + '3D_CNN' + '_' + length + '_intra subject train_stationary_test_holding accuracy.png')\n","        # plt.show()\n","        # plot_loss(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/acc and loss/' + '3D_CNN' + '_' + length + '_intra subject train_stationary_test_holding loss.png')\n","        # plt.show()\n","    print(length + \" Total Accuracy (average): \", np.mean(cvscores), np.std(cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\")\n","#-------------------------------------------------------------------------------- \n","# this part is to plot confusion matrix\n","#-------------------------------------------------------------------------------- \n","conf_mat_sum = np.sum(conf_mat_all, axis = 2)\n","plot_confusion_matrix(conf_mat_sum, classes = gestures, cmap = plt.cm.Blues, normalize = True)\n","# plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/confusion matrix/' + '3D_CNN_' + '_train_stationary_test_holding confusion_matrix.png')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MjTDNR2cHIDE"},"source":["# Inter subject (same posture)"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"912UCVwiHIDF","executionInfo":{"status":"error","timestamp":1603939414438,"user_tz":-480,"elapsed":80095,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}},"outputId":"51a50872-6cb8-41d6-8896-1a0974178ed6","colab":{"base_uri":"https://localhost:8080/","height":587}},"source":["# These list can be iterated throgh for loop\n","times = ['2s','1s','0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","#-------------------------------------------------------------------------------- \n","# this part is to define input data shape and confusion matrix\n","#-------------------------------------------------------------------------------- \n","conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","for length in times:\n","    cvscores = []\n","    print('Now, start for ' + length)\n","    if length == '2s' :\n","        input_shape = (1, 120, 8, 8)\n","    elif length == '1s':\n","        input_shape = (1, 60, 8, 8)\n","    else:\n","        input_shape = (1, 30, 8, 8)\n","        \n","#-------------------------------------------------------------------------------- \n","# this part is to load data and perform 10-fold cross validation\n","#--------------------------------------------------------------------------------  \n","    for i in range(1,11):\n","        # train data\n","        train_data, train_olabel = load_random_subject(length, 'stationary', 'train', i)\n","        test_data, test_olabel = load_random_subject(length, 'stationary', 'test', i) \n","        print('Now, start the cv: ',i)\n","        model = cnn_3d(input_shape = input_shape, learning_rate = 1e-3)\n","        history = model.fit(train_data,train_olabel,epochs = 15, batch_size = 32,verbose = 2,shuffle = True,\n","                          validation_data = (test_data,test_olabel))\n","        pred = np.argmax(model.predict(test_data), axis = 1)\n","        real_label = onehot_to_label(test_olabel)\n","        scores = accuracy_score(real_label, pred) * 100\n","        print(\"The accuracy in this fold: %f\"%scores)\n","        print(\"=============================\")\n","        cvscores.append(scores)\n","        conf_mat = np.expand_dims(confusion_matrix(real_label, pred), axis = 2)\n","        conf_mat_all = np.concatenate([conf_mat_all, conf_mat], axis = 2)\n","#-------------------------------------------------------------------------------- \n","# this part is to plot acc, loss curve and print out the average accuracy\n","#-------------------------------------------------------------------------------- \n","        # plot_acc(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/acc and loss/' + '3D_CNN' + '_' + length + '_inter subject (stationary) accuracy.png')\n","        # plt.show()\n","        # plt.plot(history.history['loss'])\n","        # plt.plot(history.history['val_loss'])\n","        # plot_loss(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/acc and loss/' + '3D_CNN' + '_' + length + '_inter subject (stationary) loss.png')\n","        # plt.show()\n","    print(length + \" Total Accuracy (average): \", np.mean(cvscores), np.std(cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\")\n","#-------------------------------------------------------------------------------- \n","# this part is to plot confusion matrix\n","#-------------------------------------------------------------------------------- \n","conf_mat_sum = np.sum(conf_mat_all, axis = 2)\n","plot_confusion_matrix(conf_mat_sum, classes = gestures, cmap = plt.cm.Blues,\n","                  normalize = True)\n","plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/confusion matrix/' + '3D_CNN' + ' stationary '+ ' inter_subject confusion_matrix.png')\n","plt.show()\n","#-------------------------------------------------------------------------------- "],"execution_count":16,"outputs":[{"output_type":"stream","text":["Now, start for 2s\n","Now, start the cv:  1\n","Epoch 1/15\n","WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0371s vs `on_train_batch_end` time: 0.0577s). Check your callbacks.\n","206/206 - 19s - loss: 1.5305 - accuracy: 0.4048 - val_loss: 1.4385 - val_accuracy: 0.3679\n","Epoch 2/15\n","206/206 - 18s - loss: 1.1350 - accuracy: 0.5962 - val_loss: 1.0146 - val_accuracy: 0.6190\n","Epoch 3/15\n","206/206 - 18s - loss: 0.7920 - accuracy: 0.7234 - val_loss: 0.7232 - val_accuracy: 0.6917\n","Epoch 4/15\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-863d4fce0294>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         history = model.fit(train_data,train_olabel,epochs = 15, batch_size = 32,verbose = 2,shuffle = True,\n\u001b[0;32m---> 28\u001b[0;31m                           validation_data = (test_data,test_olabel))\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mreal_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot_to_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_olabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"nYlaFhn_HIDH"},"source":["# These list can be iterated throgh for loop\n","times = ['2s','1s','0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","#-------------------------------------------------------------------------------- \n","# this part is to define input data shape and confusion matrix\n","#-------------------------------------------------------------------------------- \n","conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","for length in times:\n","    print('Now, start for ' + length)\n","    if length == '2s' :\n","        input_shape = (1, 120, 8, 8)\n","    elif length == '1s':\n","        input_shape = (1, 60, 8, 8)\n","    else:\n","        input_shape = (1, 30, 8, 8)\n","        \n","    cvscores = []\n","#-------------------------------------------------------------------------------- \n","# this part is to load data and perform 10-fold cross validation\n","#--------------------------------------------------------------------------------  \n","    for i in range(1,11):\n","        # train data\n","        train_data, train_olabel = load_random_subject(length, 'holding', 'train', i)\n","        test_data, test_olabel = load_random_subject(length, 'holding', 'test', i) \n","        print('Now, start the cv: ',i)\n","        model = cnn_3d(input_shape = input_shape, learning_rate = 1e-3)\n","        history = model.fit(train_data,train_olabel,epochs = 15, batch_size = 32,verbose = 0,shuffle = True,\n","                          validation_data = (test_data,test_olabel))\n","        pred = np.argmax(model.predict(test_data), axis = 1)\n","        real_label = onehot_to_label(test_olabel)\n","        scores = accuracy_score(real_label, pred) * 100\n","        print(\"The accuracy in this fold: %f\"%scores)\n","        print(\"=============================\")\n","        cvscores.append(scores)\n","        conf_mat = np.expand_dims(confusion_matrix(real_label, pred), axis = 2)\n","        conf_mat_all = np.concatenate([conf_mat_all, conf_mat], axis = 2)\n","#-------------------------------------------------------------------------------- \n","# this part is to plot acc, loss figire and print out the average accuracy\n","#-------------------------------------------------------------------------------- \n","        plot_acc(history)\n","        plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/acc and loss/' + '3D_CNN' + '_' + length + '_inter subject (holding) accuracy.png')\n","        plt.show()\n","        plot_loss(history)\n","        plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/acc and loss/' + '3D_CNN' + '_' + length + '_inter subject (holding) loss.png')\n","        plt.show()\n","    print(length + \" Total Accuracy (average): \", np.mean(cvscores), np.std(cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\")\n","#-------------------------------------------------------------------------------- \n","# this part is to plot confusion matrix\n","#--------------------------------------------------------------------------------       \n","conf_mat_sum = np.sum(conf_mat_all, axis = 2)\n","plot_confusion_matrix(conf_mat_sum, classes = gestures, cmap = plt.cm.Blues,\n","                  normalize = True)\n","plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/confusion matrix/' + '3D_CNN' + ' holding '+ ' inter_subject confusion_matrix.png')\n","plt.show()\n","#-------------------------------------------------------------------------------- "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P5iofGhCHIDJ"},"source":["# Inter Subject (different posture)"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"y3YZmQhLHIDJ"},"source":["# These list can be iterated throgh for loop\n","times = ['2s','1s','0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","#-------------------------------------------------------------------------------- \n","# this part is to define input data shape and confusion matrix\n","#-------------------------------------------------------------------------------- \n","conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","for length in times:\n","    print('Now, start for ' + length)\n","    if length == '2s' :\n","        input_shape = (1, 120, 8, 8)\n","    elif length == '1s':\n","        input_shape = (1, 60, 8, 8)\n","    else:\n","        input_shape = (1, 30, 8, 8)\n","        \n","    cvscores = []\n","    for i in range(1,11):\n","#-------------------------------------------------------------------------------- \n","# this part is to load data and perform 10-fold cross validation\n","#-------------------------------------------------------------------------------- \n","        # train data\n","        train_data, train_olabel = load_random_subject(length, 'stationary', 'train', i)\n","        test_data, test_olabel = load_random_subject(length, 'holding', 'test', i) \n","        print('Now, start the cv: ',i)\n","        model = cnn_3d(input_shape = input_shape, learning_rate = 1e-3)\n","        history = model.fit(train_data,train_olabel,epochs = 15, batch_size = 32,verbose = 0,shuffle = True,\n","                          validation_data = (test_data,test_olabel))\n","        model.evaluate(test_data,test_olabel,verbose = 0)\n","        pred = np.argmax(model.predict(test_data), axis = 1)\n","        real_label = onehot_to_label(test_olabel)\n","        scores = accuracy_score(real_label, pred) * 100\n","        print(\"The accuracy in this fold: %f\"%scores)\n","        print(\"=============================\")\n","        cvscores.append(scores)\n","        conf_mat = np.expand_dims(confusion_matrix(real_label, pred), axis = 2)\n","        conf_mat_all = np.concatenate([conf_mat_all, conf_mat], axis = 2)\n","#-------------------------------------------------------------------------------- \n","# this part is to plot acc, loss curve and print out the average accuracy\n","#-------------------------------------------------------------------------------- \n","        plot_acc(history)\n","        plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/acc and loss/' + '3D_CNN' + '_' + length + '_inter subject (train stationary test holding) accuracy.png')\n","        plt.show()\n","        plot_loss(history)\n","        plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/acc and loss/' + '3D_CNN' + '_' + length + '_inter subject (train stationary test holding) loss.png')\n","        plt.show()\n","    print(length + \" Total Accuracy (average): \", np.mean(cvscores), np.std(cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\")\n","#-------------------------------------------------------------------------------- \n","# this part is to plot confusion matrix\n","#--------------------------------------------------------------------------------    \n","conf_mat_sum = np.sum(conf_mat_all, axis = 2)\n","plot_confusion_matrix(conf_mat_sum, classes = gestures, cmap = plt.cm.Blues,\n","                  normalize = True)\n","plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/confusion matrix/' + '3D_CNN' + ' (train stationary test holding) '+ ' inter_subject confusion_matrix.png')\n","plt.show()\n","#-------------------------------------------------------------------------------- "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"B210FIEPHIDM"},"source":["# These list can be iterated throgh for loop\n","times = ['2s','1s','0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","#-------------------------------------------------------------------------------- \n","# this part is to define input data shape and confusion matrix\n","#-------------------------------------------------------------------------------- \n","conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","for length in times:\n","    print('Now, start for ' + length)\n","    if length == '2s' :\n","        input_shape = (1, 120, 8, 8)\n","    elif length == '1s':\n","        input_shape = (1, 60, 8, 8)\n","    else:\n","        input_shape = (1, 30, 8, 8)\n","        \n","    cvscores = []\n","#-------------------------------------------------------------------------------- \n","# this part is to load data and perform 10-fold cross validation\n","#-------------------------------------------------------------------------------- \n","    for i in range(1,11):\n","        # train data\n","        train_data, train_olabel = load_random_subject(length, 'holding', 'train', i)\n","        test_data, test_olabel = load_random_subject(length, 'stationary', 'test', i) \n","        print('Now, start the cv: ',i)\n","        model = cnn_3d(input_shape = input_shape, learning_rate = 1e-3)\n","        history = model.fit(train_data,train_olabel,epochs = 15, batch_size = 32,verbose = 0,shuffle = True,\n","                          validation_data=(test_data,test_olabel))\n","        model.evaluate(test_data,test_olabel,verbose = 0)\n","        pred = np.argmax(model.predict(test_data), axis = 1)\n","        real_label = onehot_to_label(test_olabel)\n","        scores = accuracy_score(real_label, pred) * 100\n","        print(\"The accuracy in this fold: %f\"%scores)\n","        print(\"=============================\")\n","        cvscores.append(scores)\n","        conf_mat = np.expand_dims(confusion_matrix(real_label, pred), axis = 2)\n","        conf_mat_all = np.concatenate([conf_mat_all, conf_mat], axis = 2)\n","#-------------------------------------------------------------------------------- \n","# this part is to plot acc, loss curve and print out the average accuracy\n","#-------------------------------------------------------------------------------- \n","        plot_acc(history)\n","        plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/acc and loss/' + '3D_CNN' + '_' + length + '_inter subject (train holding test stationary.png')\n","        plt.show()\n","        plot_loss(history)\n","        plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/acc and loss/' + '3D_CNN' + '_' + length + '_inter subject (train holding test stationary) loss.png')\n","        plt.show()\n","    print(length + \" Total Accuracy (average): \", np.mean(cvscores), np.std(cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\")\n","#-------------------------------------------------------------------------------- \n","# this part is to plot confusion matrix\n","#--------------------------------------------------------------------------------        \n","conf_mat_sum = np.sum(conf_mat_all, axis = 2)\n","plot_confusion_matrix(conf_mat_sum, classes = gestures, cmap = plt.cm.Blues,\n","                  normalize = True)\n","plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/confusion matrix/' + '3D_CNN' + ' (train holding test stationary) '+ ' inter_subject confusion_matrix.png')\n","plt.show()\n","#-------------------------------------------------------------------------------- "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DEyDATAvHIDP"},"source":["# Inter Subject (combine)"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"SylQ1JKDHIDP"},"source":["# These list can be iterated throgh for loop\n","times = ['2s', '1s', '0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","#-------------------------------------------------------------------------------- \n","# this part is to define input data shape and confusion matrix\n","#-------------------------------------------------------------------------------- \n","s_conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","for length in times:\n","    print('Now, start for ' + length)\n","    if length == '2s' :\n","        input_shape = (1, 120, 8, 8)\n","    elif length == '1s':\n","        input_shape = (1, 60, 8, 8)\n","    else:\n","        input_shape = (1, 30, 8, 8)   \n","#-------------------------------------------------------------------------------- \n","# this part is to load data and perform 10-fold cross validation\n","#--------------------------------------------------------------------------------         \n","    s_cvscores = []\n","    for i in range(1,11):\n","        s_train_data, s_train_olabel = load_random_subject(length, 'stationary', 'train',  i)\n","        h_train_data, h_train_olabel = load_random_subject(length, 'holding', 'train', i)\n","        half_s_train_data, half_s_train_olabel, half_h_train_data, half_h_train_olabel = random_select(s_train_data, s_train_olabel, h_train_data, h_train_olabel)\n","        t_train_data = np.concatenate((half_s_train_data, half_h_train_data))\n","        t_train_olabel = np.concatenate((half_s_train_olabel, half_h_train_olabel))\n","        s_test_data, s_test_olabel = load_random_subject(length, 'stationary', 'test', i)\n","        print('Now, start the cv: ',i)\n","        model = cnn_3d(input_shape = input_shape, learning_rate = 1e-3)\n","        history = model.fit(t_train_data,t_train_olabel,epochs = 15, batch_size = 32,verbose = 0, shuffle = True,\n","                            validation_data = (s_test_data, s_test_olabel))\n","        s_pred = np.argmax(model.predict(s_test_data), axis = 1)\n","        s_real_label = onehot_to_label(s_test_olabel)\n","        s_scores = accuracy_score(s_real_label, s_pred) * 100\n","        print(\"The accuracy in this fold (test stationary): %f\"%s_scores)\n","        print('The accuracy in this fold (test holding): %f'%h_scores)\n","        print(\"=============================\")\n","        s_cvscores.append(s_scores)\n","        s_conf_mat = np.expand_dims(confusion_matrix(s_real_label, s_pred), axis = 2)\n","        s_conf_mat_all = np.concatenate([s_conf_mat_all, s_conf_mat], axis = 2)\n","#-------------------------------------------------------------------------------- \n","# this part is to plot acc, loss curve and print out the average accuracy\n","#-------------------------------------------------------------------------------- \n","        plot_acc(history)\n","        plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/acc and loss/' + '3D_CNN' + '_' + length + '_inter subject (combine test stationary).png')\n","        plt.show()\n","        plot_loss(history)\n","        plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/acc and loss/' + '3D_CNN' + '_' + length + '_inter subject (combine test stationary) loss.png')\n","        plt.show()\n","    print('Test : stationary')\n","    print(length + \" Total Accuracy (average): \", np.mean(s_cvscores), np.std(s_cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\")\n","#-------------------------------------------------------------------------------- \n","# this part is to plot confusion matrix\n","#--------------------------------------------------------------------------------       \n","plot_confusion_matrix(s_conf_mat_sum, classes = gestures, cmap = plt.cm.Blues,\n","                  normalize = True)\n","plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/confusion matrix/' + '3D_CNN' + ' combine_half_test_stationary ' + ' inter_subject confusion_matrix.png')\n","plt.show()\n","#--------------------------------------------------------------------------------  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"fDwxW3rtHIDT"},"source":["# These list can be iterated throgh for loop\n","times = ['2s', '1s', '0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","#-------------------------------------------------------------------------------- \n","# this part is to define input data shape and confusion matrix\n","#-------------------------------------------------------------------------------- \n","h_conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","for length in times:\n","    print('Now, start for ' + length)\n","    if length == '2s' :\n","        input_shape = (1, 120, 8, 8)\n","    elif length == '1s':\n","        input_shape = (1, 60, 8, 8)\n","    else:\n","        input_shape = (1, 30, 8, 8)\n","#-------------------------------------------------------------------------------- \n","# this part is to load data and perform 10-fold cross validation\n","#--------------------------------------------------------------------------------        \n","    h_cvscores = []\n","    for i in range(1,11):\n","        s_train_data, s_train_olabel = load_random_subject(length, 'stationary', 'train',  i)\n","        h_train_data, h_train_olabel = load_random_subject(length, 'holding', 'train', i)\n","        half_s_train_data, half_s_train_olabel, half_h_train_data, half_h_train_olabel = random_select(s_train_data, s_train_olabel, h_train_data, h_train_olabel)\n","        t_train_data = np.concatenate((half_s_train_data, half_h_train_data))\n","        t_train_olabel = np.concatenate((half_s_train_olabel, half_h_train_olabel))\n","        h_test_data, h_test_olabel = load_random_subject(length, 'holding', 'test', i)\n","        print('Now, start the cv: ',i)\n","        model = cnn_3d(input_shape = input_shape, learning_rate = 1e-3)\n","        history = model.fit(t_train_data,t_train_olabel,epochs = 15, batch_size = 32,verbose = 0, shuffle = True,\n","                            validation_data = (h_test_data, h_test_olabel))\n","        h_pred = np.argmax(model.predict(h_test_data), axis = 1)\n","        h_real_label = onehot_to_label(h_test_olabel)\n","        h_scores = accuracy_score(h_real_label, h_pred) * 100\n","        print(\"The accuracy in this fold (test stationary): %f\"%s_scores)\n","        print('The accuracy in this fold (test holding): %f'%h_scores)\n","        print(\"=============================\")\n","        h_cvscores.append(h_scores)\n","        h_conf_mat = np.expand_dims(confusion_matrix(h_real_label, h_pred), axis = 2)\n","        h_conf_mat_all = np.concatenate([h_conf_mat_all, h_conf_mat], axis = 2)\n","#-------------------------------------------------------------------------------- \n","# this part is to plot acc, loss curve and print out the average accuracy\n","#-------------------------------------------------------------------------------- \n","        plot_acc(history)\n","        plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/acc and loss/' + '3D_CNN' + '_' + length + '_inter subject (combine test holding).png')\n","        plt.show()\n","        plot_loss(history)\n","        plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/acc and loss/' + '3D_CNN' + '_' + length + '_inter subject (combine test holding) loss.png')\n","        plt.show()\n","    print('Test : holding')\n","    print(length + \" Total Accuracy (average): \", np.mean(h_cvscores), np.std(h_cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\")\n","#-------------------------------------------------------------------------------- \n","# this part is to plot confusion matrix\n","#--------------------------------------------------------------------------------     \n","plot_confusion_matrix(h_conf_mat_sum, classes = gestures, cmap = plt.cm.Blues,\n","                  normalize = True)\n","plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/3D_CNN/confusion matrix/' + '3D_CNN' + ' combine_half_test_holding ' + ' inter_subject confusion_matrix.png')\n","plt.show()\n","#-------------------------------------------------------------------------------- "],"execution_count":null,"outputs":[]}]}