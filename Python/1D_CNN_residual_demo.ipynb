{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"name":"1D_CNN_residual_demo.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2bK7GMk64ep_"},"source":["# Import library"]},{"cell_type":"code","metadata":{"id":"0QQkiHtd5doy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604335051754,"user_tz":-480,"elapsed":36174,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}},"outputId":"d9efe62e-81d0-458e-9c9b-f21a9bf33289"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"DAaAgh_l4eqA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604335056441,"user_tz":-480,"elapsed":2848,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}},"outputId":"415c40a4-c42b-4577-939e-c84d1f111839"},"source":["import os\n","import random\n","import pickle \n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","from matplotlib import pyplot as plt\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","print(\"tf version:\", tf.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tf version: 2.3.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yTKDqBRw4eqH"},"source":["# Set random seed"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"HQcUyan84eqH"},"source":["os.environ['PYTHONHASHSEED']=str(1)\n","os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # new flag present in tf 2.0+\n","random.seed(1)\n","np.random.seed(1)\n","tf.random.set_seed(1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B0wy8kTa4eqL"},"source":["# Limit GPU resource"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"1uXvLLdB4eqL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604045575793,"user_tz":-480,"elapsed":6138,"user":{"displayName":"F94056152羅翊芳","photoUrl":"","userId":"14159951463955383384"}},"outputId":"e06ad562-54f6-41df-af1e-d5cd92792de6"},"source":["gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","  try:\n","    # Currently, memory growth needs to be the same across GPUs\n","    for gpu in gpus:\n","      tf.config.experimental.set_memory_growth(gpu, True)\n","    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","  except RuntimeError as e:\n","    # Memory growth must be set before GPUs have been initialized\n","    print(e)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1 Physical GPUs, 1 Logical GPUs\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ur7TQmBC4eqO"},"source":["# Plot acc and loss figure"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"Vu_jHFrD4eqP"},"source":["def plot_acc(train_history):\n","    \"\"\"\n","    This function is used for plot accuracy curve\n","    during training process\n","    -----------\n","    train_history : variables names of training process\n","    \"\"\"\n","    plt.plot(train_history.history['accuracy'])\n","    plt.plot(train_history.history['val_accuracy'])\n","    plt.title('Train History')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy')\n","    plt.legend(['train', 'validation'], loc = 'upper left')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"QHuspdn74eqS"},"source":["def plot_loss(train_history):\n","    \"\"\"\n","    This function is used for plot loss curve\n","    during training process\n","    Parameters\n","    -----------\n","    train_history : variables names of training process\n","    \"\"\"\n","    plt.plot(train_history.history['loss'])\n","    plt.plot(train_history.history['val_loss'])\n","    plt.title('Train History')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend(['train', 'validation'], loc = 'upper left')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rTPPIlNr4eqW"},"source":["# Plot confusion matrix"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"ZCgdFBa94eqX"},"source":["def plot_confusion_matrix(cm, classes,\n","                          normalize = False,\n","                          title = 'Confusion matrix',\n","                          cmap = plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \n","    Parameter\n","    ---------\n","    cm : confusion matrix\n","    classes : various category\n","    normalize : True, False\n","    title : you can type anthing you in it, but the data type must be \"string\"\n","    default 'Confusion matrix'\n","    cmap : default 'plt.cm.Blues'\n","    reference : https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            plt.text(j, i, format(cm[i, j], fmt),\n","                     horizontalalignment = \"center\",\n","                     color = \"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    plt.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JQspoANa4eqc"},"source":["# one hot encoder"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"A4jQ0FiR4eqd"},"source":["def onehot_to_label(data):\n","    \"\"\"\n","    This function is used for transform one hot encoding\n","    to label encoding\n","    \n","    Parameters\n","    -----------\n","    data : array-like of shape (n_samples, n_category)\n","    \n","    Returns\n","    -------\n","    label encoder\n","    \"\"\"\n","    label = []\n","    for i in range(len(data)):\n","        for j in range(len(data[i])):\n","            if data[i][j] == 1:\n","                label.append(j)\n","    return label"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XUnW-IGW4eqg"},"source":["# Load data intra subject"]},{"cell_type":"code","metadata":{"id":"R8e7IB1O4eqg"},"source":["def load_data(time, condition):\n","    \n","    \"\"\"\n","    This function is used for load pickle file\n","    from same folder\n","    \n","    Parameters\n","    ----------\n","    time : '2s', '1s', '0.5s'\n","    condition : 'stationary', 'holding'\n","    \n","    Returns\n","    -------\n","    data : tensor-like of shape (number_of_samples, time_length, 64)\n","    label : label of each category\n","    \"\"\"\n","    \n","    labels = []\n","    gesture_type = 1\n","    gestures = ['pat', 'stroke', 'grab', 'poke', 'scratch', 'notouch']\n","    pickle_path = '/content/drive/My Drive/研究資料(共用)/pickle/' + condition + ' test'\n","    if time == '2s':\n","        data = np.zeros((1, 120, 64))\n","    elif time == '1s':\n","        data = np.zeros((1, 60, 64))\n","    else:\n","        data = np.zeros((1, 30, 64))\n","    \n","    if condition == 'stationary': \n","        for gesture in gestures:\n","            file_name = 'raw_data_' + gesture + '_' + time + '_s1s25_s_1d.pck1'\n","            pickle_file = open(os.path.join(pickle_path, file_name), 'rb')\n","            array = pickle.load(pickle_file)\n","            pickle_file.close()\n","            data = np.concatenate((data, array))\n","            label = [gesture_type for i in range(len(array))]\n","            labels = np.concatenate((labels, label))\n","            gesture_type += 1\n","    else:\n","        for gesture in gestures:\n","            file_name = 'raw_data_' + gesture + '_' + time + '_s1s25_h_1d.pck1'\n","            pickle_file = open(os.path.join(pickle_path, file_name), 'rb')\n","            array = pickle.load(pickle_file)\n","            pickle_file.close()\n","            data = np.concatenate((data, array))\n","            label = [gesture_type for i in range(len(array))]\n","            labels = np.concatenate((labels, label))\n","            gesture_type += 1\n","            \n","    o_label = np.array(pd.get_dummies(labels))\n","    data = data[1:]\n","    data = data.astype('float32')\n","    return data, o_label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X8MrL4FU0pvt"},"source":["data, o_label = load_data('2s', 'stationary')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tOXR5S-Z4eqj"},"source":["# load data inter subject"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"15dFlwIZ4eqk"},"source":["def load_random_subject(time, condition_1, condition_2, folder):\n","    \n","    \"\"\"\n","    This function is used for load pickle file\n","    from various folder\n","    \n","    Parameters\n","    ----------\n","    time : '2s', '1s', '0.5s'\n","    condition_1 : 'stationary', 'holding'\n","    condition_2 : 'train', 'test'\n","    folder : 1, 2, 3, ...10\n","    \n","    Returns\n","    -------\n","    data : tensor-like of shape (total samples, time_length, 64)\n","    label : label of each category\n","    \"\"\"\n","    labels = []\n","    gestures = ['pat', 'stroke', 'grab', 'poke', 'scratch', 'notouch']\n","    gesture_type = 1\n","    pickle_path = '/content/drive/My Drive/研究資料(共用)/different subject train test/'\\\n","     + '1d_' + condition_1 + '_s1s25' + '/cv_' + str(folder)\n","    if time == '2s':\n","        data = np.zeros((1,120, 64))\n","    elif time == '1s':\n","        data = np.zeros((1,60, 64))\n","    else:\n","        data = np.zeros((1,30, 64))\n","                                \n","    if condition_1 == 'stationary':\n","        for gesture in gestures:\n","            file_name = 'raw_data_' + condition_2 + '_' + gesture + '_' + time + '_s1s25_s_1d_cv_' + str(folder) + '.pck1'\n","            pickle_file = open(os.path.join(pickle_path, file_name), 'rb')\n","            array = pickle.load(pickle_file)\n","            pickle_file.close()\n","            data = np.concatenate((data, array))\n","            label = [gesture_type for i in range(len(array))]\n","            labels = np.concatenate((labels, label))\n","            gesture_type += 1\n","    else:\n","        for gesture in gestures:\n","            file_name = 'raw_data_' + condition_2 + '_' + gesture + '_' + time + '_s1s25_h_1d_cv_' + str(folder) + '.pck1'\n","            pickle_file = open(os.path.join(pickle_path, file_name), 'rb')\n","            array = pickle.load(pickle_file)\n","            pickle_file.close()\n","            data = np.concatenate((data, array))\n","            label = [gesture_type for i in range(len(array))]\n","            labels = np.concatenate((labels, label))\n","            gesture_type += 1\n","              \n","    o_label = np.array(pd.get_dummies(labels))\n","    data = data[1:]\n","    data = data.astype('float32')\n","    return data, o_label"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B2VQ750r4eqn"},"source":["# Random select data"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"EEMYP9Z04eqo"},"source":["def random_select(s_data, s_olabel, h_data, h_olabel):\n","    \"\"\"\n","    This function can shuffle the data\n","    \n","    Parameter\n","    ---------\n","    s_data: data from stationary dataset\n","    s_olabel : label from stationary dataset\n","    h_data: data from holding dataset\n","    h_olabel : label from holding dataset\n","    \n","    Returns\n","    -------\n","    half of numbers of each posture dataset\n","    \"\"\"\n","    len_s = len(s_olabel)\n","    len_h = len(h_olabel)\n","    s_randomize = np.arange(len_s)\n","    h_randomize = np.arange(len_h)\n","    np.random.shuffle(s_randomize)\n","    np.random.shuffle(h_randomize)\n","    half_s_data = s_data[s_randomize[:int(0.5 * len_s)]]\n","    half_h_data = h_data[h_randomize[:int(0.5 * len_h)]]\n","    half_s_olabel = s_olabel[s_randomize[:int(0.5 * len_s)]]\n","    half_h_olabel = h_olabel[h_randomize[:int(0.5 * len_h)]]\n","    \n","    return half_s_data, half_s_olabel, half_h_data, half_h_olabel"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X8HZAJi84eqr"},"source":["# Identity_block"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"M0XlhNGu4eqr"},"source":["def identity_block(X, f, filters):\n","    \"\"\"\n","    This function is used for build the fundamental \n","    residual block\n","    \n","    Parameter\n","    ---------\n","    X : input data\n","    f : filter size\n","    filters: numbers of filters\n","    \n","    Returns\n","    -------\n","    tensor-like shape\n","    \"\"\"\n","    # Retrive Filters\n","    f1, f2, f3 = filters\n","    # Save input value\n","    x_shortcut = X\n","    \n","    # first component of main path\n","    \n","    x = tf.keras.layers.Conv1D(f1, kernel_size = 1, padding = 'same', kernel_initializer = 'he_uniform')(X)\n","    x = tf.keras.layers.BatchNormalization()(x)\n","    x = tf.keras.activations.swish(x)\n","    \n","    # second component of main path\n","    \n","    x = tf.keras.layers.Conv1D(f2, kernel_size = f, padding = 'same', kernel_initializer = 'he_uniform')(x)\n","    x = tf.keras.layers.BatchNormalization()(x)\n","    x = tf.keras.activations.swish(x)\n","    \n","    # Third component of main path\n","    \n","    x = tf.keras.layers.Conv1D(f3, kernel_size = 1, padding = 'same', kernel_initializer = 'he_uniform')(x)\n","    x = tf.keras.layers.BatchNormalization()(x)\n","    \n","    # Final step: Add shortcut value to main path, and pass it through a Swish activation\n","    x = tf.keras.layers.add([x, x_shortcut])\n","    x = tf.keras.activations.swish(x)\n","    \n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l5oKxEwQ4equ"},"source":["# Conv1D with BatchNormalization"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"4Nppoyr64eqv"},"source":["def conv1d_bn(X, filters, size):\n","    \n","    \"\"\"\n","    This function is used for build the fundamental convolutional block\n","    \n","    Parameter\n","    ---------\n","    X : input data\n","    size : filter size\n","    filters: numbers of filters\n","    \n","    Returns\n","    -------\n","    tensor-like shape\n","    \"\"\"\n","    \n","    cnn_1d = tf.keras.layers.Conv1D(filters, kernel_size = size, padding = 'same', kernel_initializer = 'he_uniform')(X)\n","    \n","    bn = tf.keras.layers.BatchNormalization()(cnn_1d)\n","    \n","    act = tf.keras.activations.swish(bn)\n","    \n","    return act"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AUFDndIu4eqy"},"source":["# Model"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"BtZ8RDkm4eqy"},"source":["def cnn_1d(input_shape, learning_rate):\n","    \n","    \"\"\"\n","    This function is used for build the model\n","    \n","    Parameter\n","    ---------\n","    input_shape : define the input shape\n","    learning_rate : define learning rate which was set in optimizer\n","    \n","    Returns\n","    -------\n","    whole model\n","    \"\"\"\n","    \n","    input_data = tf.keras.Input(shape = input_shape, name = 'input_data_shape')\n","    \n","    x = conv1d_bn(input_data, 32, 1)\n","    \n","    x = identity_block(x, 7, [8, 8, 32]) # f = 5, 7\n","    \n","    x = tf.keras.layers.MaxPool1D(pool_size = 5, padding = 'same')(x)\n","    \n","    \n","    x = identity_block(x, 7, [16, 16, 32])\n","    \n","    x = conv1d_bn(x, 64, 1)\n","    \n","    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n","    \n","    \n","    output = tf.keras.layers.Dense(6, activation = 'softmax')(x)\n","    \n","    model = tf.keras.Model(input_data, output)\n","    \n","    ranger = tfa.optimizers.Lookahead(tfa.optimizers.RectifiedAdam(lr = learning_rate, warmup_proportion = 0.1), \n","                                      sync_period = 6, slow_step_size = 0.6)\n","    \n","    model.compile(optimizer = ranger, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"hA8mI7fb4eq1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604045633212,"user_tz":-480,"elapsed":922,"user":{"displayName":"F94056152羅翊芳","photoUrl":"","userId":"14159951463955383384"}},"outputId":"ff877cab-7d37-4c32-83dd-eeaba07e8416"},"source":["cnn_1d((120, 64), 1e-3).summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_data_shape (InputLayer)   [(None, 120, 64)]    0                                            \n","__________________________________________________________________________________________________\n","conv1d (Conv1D)                 (None, 120, 32)      2080        input_data_shape[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 120, 32)      128         conv1d[0][0]                     \n","__________________________________________________________________________________________________\n","tf_op_layer_Sigmoid (TensorFlow [(None, 120, 32)]    0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","tf_op_layer_Mul (TensorFlowOpLa [(None, 120, 32)]    0           batch_normalization[0][0]        \n","                                                                 tf_op_layer_Sigmoid[0][0]        \n","__________________________________________________________________________________________________\n","tf_op_layer_Identity (TensorFlo [(None, 120, 32)]    0           tf_op_layer_Mul[0][0]            \n","__________________________________________________________________________________________________\n","conv1d_1 (Conv1D)               (None, 120, 8)       264         tf_op_layer_Identity[0][0]       \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 120, 8)       32          conv1d_1[0][0]                   \n","__________________________________________________________________________________________________\n","tf_op_layer_Sigmoid_1 (TensorFl [(None, 120, 8)]     0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","tf_op_layer_Mul_1 (TensorFlowOp [(None, 120, 8)]     0           batch_normalization_1[0][0]      \n","                                                                 tf_op_layer_Sigmoid_1[0][0]      \n","__________________________________________________________________________________________________\n","tf_op_layer_Identity_1 (TensorF [(None, 120, 8)]     0           tf_op_layer_Mul_1[0][0]          \n","__________________________________________________________________________________________________\n","conv1d_2 (Conv1D)               (None, 120, 8)       456         tf_op_layer_Identity_1[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 120, 8)       32          conv1d_2[0][0]                   \n","__________________________________________________________________________________________________\n","tf_op_layer_Sigmoid_2 (TensorFl [(None, 120, 8)]     0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","tf_op_layer_Mul_2 (TensorFlowOp [(None, 120, 8)]     0           batch_normalization_2[0][0]      \n","                                                                 tf_op_layer_Sigmoid_2[0][0]      \n","__________________________________________________________________________________________________\n","tf_op_layer_Identity_2 (TensorF [(None, 120, 8)]     0           tf_op_layer_Mul_2[0][0]          \n","__________________________________________________________________________________________________\n","conv1d_3 (Conv1D)               (None, 120, 32)      288         tf_op_layer_Identity_2[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 120, 32)      128         conv1d_3[0][0]                   \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 120, 32)      0           batch_normalization_3[0][0]      \n","                                                                 tf_op_layer_Identity[0][0]       \n","__________________________________________________________________________________________________\n","tf_op_layer_Sigmoid_3 (TensorFl [(None, 120, 32)]    0           add[0][0]                        \n","__________________________________________________________________________________________________\n","tf_op_layer_Mul_3 (TensorFlowOp [(None, 120, 32)]    0           add[0][0]                        \n","                                                                 tf_op_layer_Sigmoid_3[0][0]      \n","__________________________________________________________________________________________________\n","tf_op_layer_Identity_3 (TensorF [(None, 120, 32)]    0           tf_op_layer_Mul_3[0][0]          \n","__________________________________________________________________________________________________\n","max_pooling1d (MaxPooling1D)    (None, 24, 32)       0           tf_op_layer_Identity_3[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_4 (Conv1D)               (None, 24, 16)       528         max_pooling1d[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 24, 16)       64          conv1d_4[0][0]                   \n","__________________________________________________________________________________________________\n","tf_op_layer_Sigmoid_4 (TensorFl [(None, 24, 16)]     0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","tf_op_layer_Mul_4 (TensorFlowOp [(None, 24, 16)]     0           batch_normalization_4[0][0]      \n","                                                                 tf_op_layer_Sigmoid_4[0][0]      \n","__________________________________________________________________________________________________\n","tf_op_layer_Identity_4 (TensorF [(None, 24, 16)]     0           tf_op_layer_Mul_4[0][0]          \n","__________________________________________________________________________________________________\n","conv1d_5 (Conv1D)               (None, 24, 16)       1808        tf_op_layer_Identity_4[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 24, 16)       64          conv1d_5[0][0]                   \n","__________________________________________________________________________________________________\n","tf_op_layer_Sigmoid_5 (TensorFl [(None, 24, 16)]     0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","tf_op_layer_Mul_5 (TensorFlowOp [(None, 24, 16)]     0           batch_normalization_5[0][0]      \n","                                                                 tf_op_layer_Sigmoid_5[0][0]      \n","__________________________________________________________________________________________________\n","tf_op_layer_Identity_5 (TensorF [(None, 24, 16)]     0           tf_op_layer_Mul_5[0][0]          \n","__________________________________________________________________________________________________\n","conv1d_6 (Conv1D)               (None, 24, 32)       544         tf_op_layer_Identity_5[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 24, 32)       128         conv1d_6[0][0]                   \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 24, 32)       0           batch_normalization_6[0][0]      \n","                                                                 max_pooling1d[0][0]              \n","__________________________________________________________________________________________________\n","tf_op_layer_Sigmoid_6 (TensorFl [(None, 24, 32)]     0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","tf_op_layer_Mul_6 (TensorFlowOp [(None, 24, 32)]     0           add_1[0][0]                      \n","                                                                 tf_op_layer_Sigmoid_6[0][0]      \n","__________________________________________________________________________________________________\n","tf_op_layer_Identity_6 (TensorF [(None, 24, 32)]     0           tf_op_layer_Mul_6[0][0]          \n","__________________________________________________________________________________________________\n","conv1d_7 (Conv1D)               (None, 24, 64)       2112        tf_op_layer_Identity_6[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 24, 64)       256         conv1d_7[0][0]                   \n","__________________________________________________________________________________________________\n","tf_op_layer_Sigmoid_7 (TensorFl [(None, 24, 64)]     0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","tf_op_layer_Mul_7 (TensorFlowOp [(None, 24, 64)]     0           batch_normalization_7[0][0]      \n","                                                                 tf_op_layer_Sigmoid_7[0][0]      \n","__________________________________________________________________________________________________\n","tf_op_layer_Identity_7 (TensorF [(None, 24, 64)]     0           tf_op_layer_Mul_7[0][0]          \n","__________________________________________________________________________________________________\n","global_average_pooling1d (Globa (None, 64)           0           tf_op_layer_Identity_7[0][0]     \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 6)            390         global_average_pooling1d[0][0]   \n","==================================================================================================\n","Total params: 9,302\n","Trainable params: 8,886\n","Non-trainable params: 416\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"msiGwTIX4eq8"},"source":["# Intra Subject (same posture)"]},{"cell_type":"code","metadata":{"id":"_jxRHcmk4eq8","colab":{"base_uri":"https://localhost:8080/","height":841},"executionInfo":{"status":"error","timestamp":1604022041702,"user_tz":-480,"elapsed":75739,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}},"outputId":"d2ada869-d99e-4156-b02d-b4aaa63d2fa0"},"source":["# These list can be iterated throgh for loop\n","#--------------------------------------------------------------------------------\n","times = ['2s','1s','0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","phase = ['stationary', 'holding']\n","#--------------------------------------------------------------------------------\n","# this part is to define input data shape and load data\n","#--------------------------------------------------------------------------------\n","for c in phase:\n","    conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","    for length in times:\n","        i = 1\n","        cvscores = []\n","        print('Now start 10 fold cross validation')\n","        print('phase = ' + c)\n","        print('data_length = ' + length)\n","        print('Now, start for ' + length)\n","        if length == '2s' :\n","            input_shape = (120, 64)\n","        elif length == '1s':\n","            input_shape = (60, 64)\n","        else:\n","            input_shape = (30, 64)\n","        data, o_label = load_data(length, c)\n","        label = onehot_to_label(o_label)\n","        label = np.reshape(label, (len(label), 1))\n","#--------------------------------------------------------------------------------\n","# this part is to perform 10-fold cross validation\n","#--------------------------------------------------------------------------------\n","        k_fold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 1)\n","        for train, validate in k_fold.split(data, label):\n","            print('Now, start the cv: ',i)\n","            x_train, y_train = data[train], label[train]\n","            x_validate, y_validate = data[validate], label[validate]\n","            y_train = tf.keras.utils.to_categorical(y_train, num_classes = 6)\n","            y_val = tf.keras.utils.to_categorical(y_validate, num_classes = 6)\n","            model = cnn_1d(input_shape = input_shape, learning_rate = 0.01)\n","            history = model.fit(x_train, y_train, epochs = 25, batch_size = 32, verbose = 2, shuffle = True,\n","                               validation_data = (x_validate, y_val))\n","            pred = np.argmax(model.predict(x_validate), axis = 1)\n","            real_label = onehot_to_label(y_val)\n","            scores = accuracy_score(real_label, pred)* 100\n","            print(\"The accuracy in this fold: %f\"%scores)\n","            print(\"=============================\")\n","            cvscores.append(scores)\n","            conf_mat = np.expand_dims(confusion_matrix(y_validate, pred), axis = 2)\n","            conf_mat_all = np.concatenate([conf_mat_all, conf_mat], axis = 2)\n","            i += 1\n","#--------------------------------------------------------------------------------\n","# this part is to plot acc,loss figire and print out the average accuracy\n","#--------------------------------------------------------------------------------\n","            # plot_acc(history)\n","            # plt.savefig(path + '1D_CNN' + '_' + c + '_' + length + '_intra subject accuracy.png')\n","            # plt.show()\n","            # plot_loss(history)\n","            # plt.savefig(path + '1D_CNN' + '_' + c + '_' + length + '_intra subject loss.png')\n","            # plt.show()            \n","        print(length + \" Total Accuracy (average): \", np.mean(cvscores), np.std(cvscores))\n","        print(\"=============================================\")\n","        print(\"=============================================\")\n","#--------------------------------------------------------------------------------\n","# this part i to plot confusion matrix\n","#--------------------------------------------------------------------------------      \n","    conf_mat_sum = np.sum(conf_mat_all, axis = 2)\n","    plot_confusion_matrix(conf_mat_sum, classes = gestures, cmap = plt.cm.Blues,\n","                      normalize = True)\n","    # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/confusion matrix/' + '1D_CNN' + '_' + c + '_intra subject confusion_matrix.png')\n","    plt.show()\n","#--------------------------------------------------------------------------------"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Now start 10 fold cross validation\n","phase = stationary\n","data_length = 2s\n","Now, start for 2s\n","Now, start the cv:  1\n","Epoch 1/25\n","209/209 - 5s - loss: 1.1557 - accuracy: 0.5533 - val_loss: 0.8889 - val_accuracy: 0.6703\n","Epoch 2/25\n","209/209 - 5s - loss: 0.5242 - accuracy: 0.7912 - val_loss: 0.6630 - val_accuracy: 0.7510\n","Epoch 3/25\n","209/209 - 5s - loss: 0.3580 - accuracy: 0.8564 - val_loss: 0.4434 - val_accuracy: 0.8264\n","Epoch 4/25\n","209/209 - 5s - loss: 0.2774 - accuracy: 0.8892 - val_loss: 0.2814 - val_accuracy: 0.9098\n","Epoch 5/25\n","209/209 - 5s - loss: 0.2180 - accuracy: 0.9148 - val_loss: 0.2669 - val_accuracy: 0.9044\n","Epoch 6/25\n","209/209 - 5s - loss: 0.2040 - accuracy: 0.9216 - val_loss: 0.2716 - val_accuracy: 0.9058\n","Epoch 7/25\n","209/209 - 5s - loss: 0.1681 - accuracy: 0.9371 - val_loss: 0.2583 - val_accuracy: 0.8896\n","Epoch 8/25\n","209/209 - 5s - loss: 0.1645 - accuracy: 0.9377 - val_loss: 0.1811 - val_accuracy: 0.9394\n","Epoch 9/25\n","209/209 - 5s - loss: 0.1451 - accuracy: 0.9473 - val_loss: 0.1259 - val_accuracy: 0.9583\n","Epoch 10/25\n","209/209 - 5s - loss: 0.1328 - accuracy: 0.9493 - val_loss: 0.3104 - val_accuracy: 0.9004\n","Epoch 11/25\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-f2d0c2ca8faf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             history = model.fit(x_train, y_train, epochs = 25, batch_size = 32, verbose = 2, shuffle = True,\n\u001b[0;32m---> 39\u001b[0;31m                                validation_data = (x_validate, y_val))\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_validate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mreal_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot_to_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"N0N1SoPz4eq_"},"source":["# Intra Subject (different posture)"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"ObGtBwzi4erA","colab":{"base_uri":"https://localhost:8080/","height":550},"executionInfo":{"status":"error","timestamp":1603936351505,"user_tz":-480,"elapsed":29470,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}},"outputId":"08070bee-3780-4de5-8e30-a3d1ebbaa8c9"},"source":["# These list can be iterated throgh for loop\n","times = ['2s', '1s', '0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","#--------------------------------------------------------------------------------\n","# this part is to define input data shape and confusion matrix, then load data\n","#--------------------------------------------------------------------------------\n","conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","for length in times:\n","    cvscores = []\n","    print('Now, start for ' + length)\n","     # define input shape\n","    if length == '2s' :\n","        input_shape = (120, 64)\n","    elif length == '1s':\n","        input_shape = (60, 64)\n","    else:\n","        input_shape = (30, 64)\n","        \n","    s_data, s_o_label = load_data(length, 'stationary')\n","    h_data, h_o_label = load_data(length, 'holding')\n","#--------------------------------------------------------------------------------\n","# this part is to trained and perform 10-fold cross validation\n","#--------------------------------------------------------------------------------\n","    for i in range(1, 11):\n","        print('Now, start the cv: ',i)\n","        x_s_train, x_s_test, y_s_train, y_s_test = train_test_split(s_data, s_o_label, test_size = 0.1, shuffle = True)\n","        x_h_train, x_h_test, y_h_train, y_h_test = train_test_split(h_data, h_o_label, test_size = 0.1, shuffle = True)\n","        model = cnn_1d(input_shape = input_shape, learning_rate = 0.01)\n","        history = model.fit(x_h_train, y_h_train, epochs = 25, batch_size = 32, verbose = 2,\n","                            shuffle = True, validation_data = (x_s_test, y_s_test))\n","        pred = np.argmax(model.predict(x_s_test), axis = 1)\n","        real_label = onehot_to_label(y_s_test)\n","        scores = accuracy_score(real_label, pred) * 100\n","        print('The accuracy in this fold is: %f'%scores)\n","        conf_mat = np.expand_dims(confusion_matrix(real_label, pred), axis = 2)\n","        conf_mat_all = np.concatenate([conf_mat, conf_mat_all], axis = 2)\n","#--------------------------------------------------------------------------------\n","# this part is to plot acc and loss curve and print out the average accuracy\n","#--------------------------------------------------------------------------------       \n","        # plot_acc(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/acc and loss/' + '1D_CNN' + '_' + length + '_intra subject train_holding_test_stationary accuracy.png')\n","        # plt.show()\n","        # plot_loss(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/acc and loss/' + '1D_CNN' + '_' + length + '_intra subject train_holding_test_stationary loss.png')\n","        # plt.show()\n","        cvscores.append(scores)\n","    print(length + \" Total Accuracy (average): \", np.mean(cvscores), np.std(cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\")\n","#--------------------------------------------------------------------------------\n","# this part is to plot confusion matrix\n","#--------------------------------------------------------------------------------\n","conf_mat_sum = np.sum(conf_mat_all, axis = 2)\n","plot_confusion_matrix(conf_mat_sum, classes = gestures, cmap = plt.cm.Blues, normalize = True)\n","# plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/confusion matrix/' + '1D_CNN_' + '_train_holding_test_stationary confusion_matrix.png')\n","plt.show()\n","#--------------------------------------------------------------------------------"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Now, start for 2s\n","Now, start the cv:  1\n","Epoch 1/25\n","210/210 - 5s - loss: 1.3604 - accuracy: 0.4514 - val_loss: 1.1844 - val_accuracy: 0.4993\n","Epoch 2/25\n","210/210 - 5s - loss: 0.7195 - accuracy: 0.7201 - val_loss: 1.1038 - val_accuracy: 0.5949\n","Epoch 3/25\n","210/210 - 5s - loss: 0.4899 - accuracy: 0.8168 - val_loss: 0.9209 - val_accuracy: 0.6918\n","Epoch 4/25\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-4b7a1a4484f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         history = model.fit(x_h_train, y_h_train, epochs = 25, batch_size = 32, verbose = 2,\n\u001b[0;32m---> 30\u001b[0;31m                             shuffle = True, validation_data = (x_s_test, y_s_test))\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_s_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mreal_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot_to_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_s_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"OZPPqs4b4erD"},"source":["# These list can be iterated throgh for loop\n","times = ['2s', '1s', '0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","#--------------------------------------------------------------------------------\n","# this part is to define input data shape and confusion matrix, then load data\n","#--------------------------------------------------------------------------------\n","conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","for length in times:\n","    cvscores = []\n","    print('Now, start for ' + length)\n","    if length == '2s' :\n","        input_shape = (120, 64)\n","    elif length == '1s':\n","        input_shape = (60, 64)\n","    else:\n","        input_shape = (30, 64)\n","    s_data, s_o_label = load_data(length, 'stationary')\n","    h_data, h_o_label = load_data(length, 'holding')\n","#--------------------------------------------------------------------------------\n","# this part is to trained and perform 10-fold cross validation\n","#--------------------------------------------------------------------------------\n","    for i in range(1, 11):\n","        print('Now, start the cv: ',i)\n","        x_s_train, x_s_test, y_s_train, y_s_test = train_test_split(s_data, s_o_label, test_size = 0.1, shuffle = True)\n","        x_h_train, x_h_test, y_h_train, y_h_test = train_test_split(h_data, h_o_label, test_size = 0.1, shuffle = True)\n","        model = cnn_1d(input_shape = input_shape, learning_rate = 0.01)\n","        history = model.fit(x_s_train, y_s_train, epochs = 25, batch_size = 32, verbose = 0,\n","                            shuffle = True, validation_data = (x_h_test, y_h_test))\n","        pred = np.argmax(model.predict(x_h_test), axis = 1)\n","        real_label = onehot_to_label(y_h_test)\n","        scores = accuracy_score(real_label, pred) * 100\n","        print('The accuracy is this fold is : %f'%scores)\n","        conf_mat = np.expand_dims(confusion_matrix(real_label, pred), axis = 2)\n","        conf_mat_all = np.concatenate([conf_mat, conf_mat_all], axis = 2)\n","#--------------------------------------------------------------------------------\n","# this part is to plot acc, loss curve and print out the average accuracy\n","#--------------------------------------------------------------------------------\n","        # plot_acc(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/acc and loss/' + '1D_CNN' + '_' + length + '_intra subject train_stationary_test_holding accuracy.png')\n","        # plt.show()\n","        # plot_loss(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/acc and loss/' + '1D_CNN' + '_' + length + '_intra subject train_stationary_test_holding loss.png')\n","        # plt.show()\n","        cvscores.append(scores)\n","    print(length + \" Total Accuracy (average): \", np.mean(cvscores), np.std(cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\")\n","#--------------------------------------------------------------------------------\n","# this part is to plot confusion matrix\n","#--------------------------------------------------------------------------------\n","conf_mat_sum = np.sum(conf_mat_all, axis = 2)\n","plot_confusion_matrix(conf_mat_sum, classes = gestures, cmap = plt.cm.Blues, normalize = True)\n","# plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/confusion matrix/' + '1D_CNN_' + '_train_stationary_test_holding confusion_matrix.png')\n","plt.show()\n","#--------------------------------------------------------------------------------"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WYpb2x7X4erF"},"source":["# Inter subject (same posture)"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"vZWIgT104erG","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1603936604718,"user_tz":-480,"elapsed":214406,"user":{"displayName":"P86071058陳瑋泰","photoUrl":"","userId":"13774398260147724666"}},"outputId":"ec09d828-c3f4-4448-b9fb-6a0dd58b050f"},"source":["# These list can be iterated throgh for loop\n","times = ['2s','1s','0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","#--------------------------------------------------------------------------------\n","# this part is to define input data shape and confusion matrix\n","#--------------------------------------------------------------------------------\n","conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","for length in times:\n","    cvscores = []\n","    print('Now, start for ' + length)\n","    if length == '2s' :\n","        input_shape = (120, 64)\n","    elif length == '1s':\n","        input_shape = (60, 64)\n","    else:\n","        input_shape = (30, 64)    \n","#--------------------------------------------------------------------------------\n","# this part is to load data and perform 10-fold cross validation\n","#--------------------------------------------------------------------------------  \n","    for i in range(1,11):\n","        train_data, train_olabel = load_random_subject(length, 'stationary', 'train', i)\n","        test_data, test_olabel = load_random_subject(length, 'stationary', 'test', i) \n","        print('Now, start the cv: ',i)\n","        model = cnn_1d(input_shape = input_shape, learning_rate = 1e-3)\n","        history = model.fit(train_data,train_olabel,epochs = 25, batch_size = 32,verbose = 2,shuffle = True,\n","                          validation_data=(test_data,test_olabel))\n","        pred = np.argmax(model.predict(test_data), axis = 1)\n","        real_label = onehot_to_label(test_olabel)\n","        scores = accuracy_score(real_label, pred) * 100\n","        print(\"The accuracy in this fold: %f\"%scores)\n","        print(\"=============================\")\n","        cvscores.append(scores)\n","        conf_mat = np.expand_dims(confusion_matrix(real_label, pred), axis = 2)\n","        conf_mat_all = np.concatenate([conf_mat_all, conf_mat], axis = 2)\n","#--------------------------------------------------------------------------------\n","# this part is to plot acc, loss curve and print out the average accuracy\n","#--------------------------------------------------------------------------------\n","        # plot_acc(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/acc and loss' + '1D_CNN' + '_' + length + '_inter subject (stationary) accuracy.png')\n","        # plt.show()\n","        # plot_loss(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/acc and loss' + '1D_CNN' + '_' + length + '_inter subject (stationary) loss.png')\n","        # plt.show()\n","    print(length + \" Total Accuracy (average): \", np.mean(cvscores), np.std(cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\")\n","#--------------------------------------------------------------------------------\n","# this part is to plot confusion matrix\n","#--------------------------------------------------------------------------------\n","conf_mat_sum = np.sum(conf_mat_all, axis = 2)\n","plot_confusion_matrix(conf_mat_sum, classes = gestures, cmap = plt.cm.Blues,\n","                  normalize = True)\n","# plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/confusion matrix/' + '1D_CNN' + ' stationary '+ ' inter_subject confusion_matrix.png')\n","plt.show()\n","#--------------------------------------------------------------------------------"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Now, start for 2s\n","Now, start the cv:  1\n","Epoch 1/25\n","204/204 - 6s - loss: 1.6072 - accuracy: 0.3399 - val_loss: 1.5344 - val_accuracy: 0.4411\n","Epoch 2/25\n","204/204 - 5s - loss: 1.2255 - accuracy: 0.5367 - val_loss: 1.2852 - val_accuracy: 0.4811\n","Epoch 3/25\n","204/204 - 5s - loss: 0.9479 - accuracy: 0.6201 - val_loss: 1.1284 - val_accuracy: 0.5189\n","Epoch 4/25\n","204/204 - 5s - loss: 0.7602 - accuracy: 0.6980 - val_loss: 1.0504 - val_accuracy: 0.5811\n","Epoch 5/25\n","204/204 - 5s - loss: 0.6329 - accuracy: 0.7391 - val_loss: 0.9705 - val_accuracy: 0.5967\n","Epoch 6/25\n","204/204 - 5s - loss: 0.5432 - accuracy: 0.7748 - val_loss: 1.0318 - val_accuracy: 0.5922\n","Epoch 7/25\n","204/204 - 5s - loss: 0.4892 - accuracy: 0.7973 - val_loss: 0.9053 - val_accuracy: 0.6244\n","Epoch 8/25\n","204/204 - 5s - loss: 0.4274 - accuracy: 0.8232 - val_loss: 0.9455 - val_accuracy: 0.6311\n","Epoch 9/25\n","204/204 - 5s - loss: 0.3867 - accuracy: 0.8421 - val_loss: 1.0023 - val_accuracy: 0.6122\n","Epoch 10/25\n","204/204 - 5s - loss: 0.3605 - accuracy: 0.8570 - val_loss: 0.7015 - val_accuracy: 0.7344\n","Epoch 11/25\n","204/204 - 5s - loss: 0.3278 - accuracy: 0.8723 - val_loss: 0.7429 - val_accuracy: 0.7067\n","Epoch 12/25\n","204/204 - 5s - loss: 0.2935 - accuracy: 0.8859 - val_loss: 0.8674 - val_accuracy: 0.6567\n","Epoch 13/25\n","204/204 - 5s - loss: 0.2710 - accuracy: 0.8962 - val_loss: 0.9362 - val_accuracy: 0.6633\n","Epoch 14/25\n","204/204 - 5s - loss: 0.2503 - accuracy: 0.9054 - val_loss: 0.8394 - val_accuracy: 0.7044\n","Epoch 15/25\n","204/204 - 5s - loss: 0.2399 - accuracy: 0.9059 - val_loss: 0.8120 - val_accuracy: 0.7056\n","Epoch 16/25\n","204/204 - 5s - loss: 0.2171 - accuracy: 0.9197 - val_loss: 0.9682 - val_accuracy: 0.6778\n","Epoch 17/25\n","204/204 - 5s - loss: 0.2052 - accuracy: 0.9215 - val_loss: 0.6697 - val_accuracy: 0.7444\n","Epoch 18/25\n","204/204 - 6s - loss: 0.1903 - accuracy: 0.9273 - val_loss: 0.5795 - val_accuracy: 0.7778\n","Epoch 19/25\n","204/204 - 5s - loss: 0.1705 - accuracy: 0.9341 - val_loss: 0.8345 - val_accuracy: 0.7222\n","Epoch 20/25\n","204/204 - 5s - loss: 0.1615 - accuracy: 0.9399 - val_loss: 0.7602 - val_accuracy: 0.7389\n","Epoch 21/25\n","204/204 - 5s - loss: 0.1622 - accuracy: 0.9396 - val_loss: 0.5364 - val_accuracy: 0.7967\n","Epoch 22/25\n","204/204 - 5s - loss: 0.1480 - accuracy: 0.9433 - val_loss: 0.5889 - val_accuracy: 0.7844\n","Epoch 23/25\n","204/204 - 5s - loss: 0.1444 - accuracy: 0.9462 - val_loss: 0.6711 - val_accuracy: 0.7756\n","Epoch 24/25\n","204/204 - 5s - loss: 0.1325 - accuracy: 0.9489 - val_loss: 0.8113 - val_accuracy: 0.7433\n","Epoch 25/25\n","204/204 - 5s - loss: 0.1304 - accuracy: 0.9516 - val_loss: 0.5667 - val_accuracy: 0.8111\n","The accuracy in this fold: 81.111111\n","=============================\n","Now, start the cv:  2\n","Epoch 1/25\n","204/204 - 6s - loss: 1.6854 - accuracy: 0.2930 - val_loss: 1.5448 - val_accuracy: 0.3800\n","Epoch 2/25\n","204/204 - 5s - loss: 1.3802 - accuracy: 0.4455 - val_loss: 1.3145 - val_accuracy: 0.4622\n","Epoch 3/25\n","204/204 - 5s - loss: 1.1003 - accuracy: 0.5767 - val_loss: 1.0940 - val_accuracy: 0.5789\n","Epoch 4/25\n","204/204 - 5s - loss: 0.8213 - accuracy: 0.6822 - val_loss: 0.9707 - val_accuracy: 0.6256\n","Epoch 5/25\n","204/204 - 5s - loss: 0.6600 - accuracy: 0.7369 - val_loss: 0.9493 - val_accuracy: 0.6533\n","Epoch 6/25\n","204/204 - 5s - loss: 0.5631 - accuracy: 0.7765 - val_loss: 0.9063 - val_accuracy: 0.6733\n","Epoch 7/25\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-e4e235ba92c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         history = model.fit(train_data,train_olabel,epochs = 25, batch_size = 32,verbose = 2,shuffle = True,\n\u001b[0;32m---> 26\u001b[0;31m                           validation_data=(test_data,test_olabel))\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mreal_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot_to_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_olabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"nPTQiDKf4erK"},"source":["# These list can be iterated throgh for loop\n","times = ['2s','1s','0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","#--------------------------------------------------------------------------------\n","# this part is to define input data shape and confusion matrix\n","#--------------------------------------------------------------------------------\n","for length in times:\n","    cvscores = []\n","    print('Now, start for ' + length)\n","    # define input shape\n","    if length == '2s' :\n","        input_shape = (120, 64)\n","    elif length == '1s':\n","        input_shape = (60, 64)\n","    else:\n","        input_shape = (30, 64)\n","#--------------------------------------------------------------------------------\n","# this part is to load data and perform 10-fold cross validation\n","#--------------------------------------------------------------------------------\n","    for i in range(1,11):\n","        train_data, train_olabel = load_random_subject(length, 'holding', 'train', i)\n","        test_data, test_olabel = load_random_subject(length, 'holding', 'test', i) \n","        print('Now, start the cv: ',i)\n","        model = cnn_1d(input_shape = input_shape, learning_rate = 1e-3)\n","        history = model.fit(train_data,train_olabel,epochs = 25, batch_size = 32,verbose = 0,shuffle = True,\n","                          validation_data = (test_data,test_olabel))\n","        pred = np.argmax(model.predict(test_data), axis = 1)\n","        real_label = onehot_to_label(test_olabel)\n","        scores = accuracy_score(real_label, pred) * 100\n","        print(\"The accuracy in this fold: %f\"%scores)\n","        print(\"=============================\")\n","        cvscores.append(scores)\n","        conf_mat = np.expand_dims(confusion_matrix(real_label, pred), axis = 2)\n","        conf_mat_all = np.concatenate([conf_mat_all, conf_mat], axis = 2)\n","#--------------------------------------------------------------------------------\n","# this part is to plot acc, loss curve and print out the average accuracy\n","#--------------------------------------------------------------------------------\n","        # plot_acc(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/acc and loss/' + '1D_CNN' + '_' + length + '_inter subject (holding) accuracy.png')\n","        # plt.show()\n","        # plot_loss(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/acc and loss/' + '1D_CNN' + '_' + length + '_inter subject (holding) loss.png')\n","        # plt.show()\n","    print(length + \" Total Accuracy (average): \", np.mean(cvscores), np.std(cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\")\n","#--------------------------------------------------------------------------------\n","# this part is to plot confusion matrix\n","#--------------------------------------------------------------------------------          \n","conf_mat_sum = np.sum(conf_mat_all, axis = 2)\n","plot_confusion_matrix(conf_mat_sum, classes = gestures, cmap = plt.cm.Blues,\n","                  normalize = True)\n","# plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/confusion matrix/' + '1D_CNN' + ' holding '+ ' inter_subject confusion_matrix.png')\n","plt.show()\n","#--------------------------------------------------------------------------------"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PGypFcdo4erN"},"source":["# Inter subject (different posture)"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"XzhH_PwD4erN"},"source":["# Theses list can be iterated throgh for loop\n","#--------------------------------------------------------------------------------\n","times = ['2s','1s','0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","#--------------------------------------------------------------------------------\n","# this part is to define input data shape and confusion matrix\n","#--------------------------------------------------------------------------------\n","conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","for length in times:\n","    cvscores = []\n","    print('Now, start for ' + length)\n","    if length == '2s' :\n","        input_shape = (120, 64)\n","    elif length == '1s':\n","        input_shape = (60, 64)\n","    else:\n","        input_shape = (30, 64)   \n","#--------------------------------------------------------------------------------\n","# this part is to load data and perform 10-fold cross validation\n","#--------------------------------------------------------------------------------\n","    for i in range(1,11):\n","        train_data, train_olabel = load_random_subject(length, 'stationary', 'train', i)\n","        test_data, test_olabel = load_random_subject(length, 'holding', 'test', i) \n","        print('Now, start the cv: ',i)\n","        model = cnn_1d(input_shape = input_shape, learning_rate = 1e-3)\n","        history = model.fit(train_data,train_olabel,epochs = 25, batch_size = 32,verbose = 0,shuffle = True,\n","                          validation_data=(test_data,test_olabel))\n","        pred = np.argmax(model.predict(test_data), axis = 1)\n","        real_label = onehot_to_label(test_olabel)\n","        scores = accuracy_score(real_label, pred) * 100\n","        print(\"The accuracy in this fold: %f\"%scores)\n","        print(\"=============================\")\n","        cvscores.append(scores)\n","        conf_mat = np.expand_dims(confusion_matrix(real_label, pred), axis = 2)\n","        conf_mat_all = np.concatenate([conf_mat_all, conf_mat], axis = 2)\n","#--------------------------------------------------------------------------------\n","# this part is to plot acc, loss curve and print out the average accuracy\n","#--------------------------------------------------------------------------------\n","        # plot_acc(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/acc and loss/' + '1D_CNN' + '_' + length + '_inter subject (train stationary test holding) accuracy.png')\n","        # plt.show()\n","        # plot_loss(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/acc and loss/' + '1D_CNN' + '_' + length + '_inter subject (train stationary test holding) loss.png')\n","        # plt.show()\n","    print(length + \" Total Accuracy (average): \", np.mean(cvscores), np.std(cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\")\n","#--------------------------------------------------------------------------------\n","# this part is to plot confusion matrix\n","#-------------------------------------------------------------------------------- \n","conf_mat_sum = np.sum(conf_mat_all, axis = 2)\n","plot_confusion_matrix(conf_mat_sum, classes = gestures, cmap = plt.cm.Blues,\n","                  normalize = True)\n","# plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/confusion matrix/' + '1D_CNN' + ' (train stationary test holding) '+ ' inter_subject confusion_matrix.png')\n","plt.show()\n","#--------------------------------------------------------------------------------"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"Eqpk1rE14erP"},"source":["# Theses list can be iterated throgh for loop\n","#--------------------------------------------------------------------------------\n","times = ['2s','1s','0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","#--------------------------------------------------------------------------------\n","# this part is to define input data shape and confusion matrix\n","#--------------------------------------------------------------------------------\n","conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","for length in times:\n","    cvscores = []\n","    print('Now, start for ' + length)\n","    if length == '2s' :\n","        input_shape = (120, 64)\n","    elif length == '1s':\n","        input_shape = (60, 64)\n","    else:\n","        input_shape = (30, 64)  \n","#--------------------------------------------------------------------------------\n","# this part is to load data and perform 10-fold cross validation\n","#--------------------------------------------------------------------------------\n","    for i in range(1,11):\n","        train_data, train_olabel = load_random_subject(length, 'holding', 'train', i)\n","        test_data, test_olabel = load_random_subject(length, 'stationary', 'test', i) \n","        print('Now, start the cv: ',i)\n","        model = cnn_1d(input_shape = input_shape, learning_rate = 1e-3)\n","        history = model.fit(train_data,train_olabel,epochs = 25, batch_size = 32,verbose = 0,shuffle = True,\n","                          validation_data=(test_data,test_olabel))\n","        pred = np.argmax(model.predict(test_data), axis = 1)\n","        real_label = onehot_to_label(test_olabel)\n","        scores = accuracy_score(real_label, pred) * 100\n","        print(\"The accuracy in this fold: %f\"%scores)\n","        print(\"=============================\")\n","        cvscores.append(scores)\n","        conf_mat = np.expand_dims(confusion_matrix(real_label, pred), axis = 2)\n","        conf_mat_all = np.concatenate([conf_mat_all, conf_mat], axis = 2)\n","#--------------------------------------------------------------------------------\n","# this part is to plot acc, loss curve and print out the average accuracy\n","#--------------------------------------------------------------------------------\n","        # plot_acc(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/acc and loss/' + '1D_CNN' + '_' + length + '_inter subject (train holding test stationary.png')\n","        # plt.show()\n","        # plot_loss(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/acc and loss/' + '1D_CNN' + '_' + length + '_inter subject (train holding test stationary) loss.png')\n","        # plt.show()\n","    print(length + \" Total Accuracy (average): \", np.mean(cvscores), np.std(cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\")\n","#--------------------------------------------------------------------------------\n","# this part is to plot confusion matrix\n","#--------------------------------------------------------------------------------\n","conf_mat_sum = np.sum(conf_mat_all, axis = 2)\n","plot_confusion_matrix(conf_mat_sum, classes = gestures, cmap = plt.cm.Blues,\n","                  normalize = True)\n","# plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/confusion matrix/' + '1D_CNN' + ' (train holding test stationary) '+ ' inter_subject confusion_matrix.png')\n","plt.show()\n","#--------------------------------------------------------------------------------"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vzH0g7Wq4erS"},"source":["# Inter Subject (Combine)"]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"JTfIr-Xq4erT"},"source":["# Theses list can be iterated throgh for loop\n","#--------------------------------------------------------------------------------\n","times = ['2s', '1s', '0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","#--------------------------------------------------------------------------------\n","# this part is to define input data shape and confusion matrix\n","#--------------------------------------------------------------------------------\n","s_conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","for length in times:\n","    s_cvscores = []\n","    \n","    print('Now, start for ' + length)\n","    if length == '2s' :\n","        input_shape = (120, 64)\n","    elif length == '1s':\n","        input_shape = (60, 64)\n","    else:\n","        input_shape = (30, 64)\n","#--------------------------------------------------------------------------------\n","# this part is to load data and perform 10-fold cross validation\n","#--------------------------------------------------------------------------------\n","    for i in range(1,11):\n","        s_train_data, s_train_olabel = load_random_subject(length, 'stationary', 'train',  i)\n","        h_train_data, h_train_olabel = load_random_subject(length, 'holding', 'train', i)\n","        half_s_train_data, half_s_train_olabel, half_h_train_data, half_h_train_olabel = random_select(s_train_data, s_train_olabel, h_train_data, h_train_olabel)\n","        t_train_data = np.concatenate((half_s_train_data, half_h_train_data))\n","        t_train_olabel = np.concatenate((half_s_train_olabel, half_h_train_olabel))\n","        s_test_data, s_test_olabel = load_random_subject(length, 'stationary', 'test', i)\n","        print('Now, start the cv: ',i)\n","        model = cnn_1d(input_shape = input_shape, learning_rate = 1e-3)\n","        history = model.fit(t_train_data,t_train_olabel,epochs = 25, batch_size = 32,verbose = 0, shuffle = True,\n","                            validation_data = (s_test_data, s_test_olabel))\n","        s_pred = np.argmax(model.predict(s_test_data), axis = 1)\n","        s_real_label = onehot_to_label(s_test_olabel)\n","        s_scores = accuracy_score(s_real_label, s_pred) * 100\n","        print(\"The accuracy in this fold (test stationary): %f\"%s_scores)\n","        print(\"=============================\")\n","        s_cvscores.append(s_scores)\n","        s_conf_mat = np.expand_dims(confusion_matrix(s_real_label, s_pred), axis = 2)\n","        s_conf_mat_all = np.concatenate([s_conf_mat_all, s_conf_mat], axis = 2)\n","#--------------------------------------------------------------------------------\n","# this part is to plot acc, loss curve and print out the average accuracy\n","#--------------------------------------------------------------------------------  \n","        # plot_acc(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/acc and loss/' + '1D_CNN' + '_' + length + '_inter subject (combine test stationary).png')\n","        # plt.show()\n","        # plot_loss(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/acc and loss/' + '1D_CNN' + '_' + length + '_inter subject (combine test stationary) loss.png')\n","        # plt.show()\n","    print('Test : stationary')\n","    print(length + \" Total Accuracy (average): \", np.mean(s_cvscores), np.std(s_cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\") \n","#--------------------------------------------------------------------------------\n","# this part is to plot confusion matrix\n","#--------------------------------------------------------------------------------            \n","s_conf_mat_sum = np.sum(s_conf_mat_all, axis = 2)\n","plot_confusion_matrix(s_conf_mat_sum, classes = gestures, cmap = plt.cm.Blues,\n","                  normalize = True)\n","# plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/2D_CNN/confusion matrix/' + '1D_CNN' + ' combine_half_test_stationary ' + ' inter_subject confusion_matrix.png')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"jupyter":{"source_hidden":true},"id":"a025iGPO4erW"},"source":["# Theses list can be iterated throgh for loop\n","#--------------------------------------------------------------------------------\n","times = ['2s', '1s', '0.5s']\n","gestures = ['pat','stroke','grab','poke','scratch','notouch']\n","h_conf_mat_all = np.expand_dims(np.zeros(shape = (6, 6)), axis = 2)\n","#--------------------------------------------------------------------------------\n","# this part is to define input data shape and confusion matrix\n","#--------------------------------------------------------------------------------\n","for length in times:\n","    h_cvscores = []\n","    \n","    print('Now, start for ' + length)\n","    if length == '2s' :\n","        input_shape = (120, 64)\n","    elif length == '1s':\n","        input_shape = (60, 64)\n","    else:\n","        input_shape = (30, 64)  \n","#--------------------------------------------------------------------------------\n","# this part is to load data and perform 10-fold cross validation\n","#-------------------------------------------------------------------------------- \n","    for i in range(1,11):\n","        s_train_data, s_train_olabel = load_random_subject(length, 'stationary', 'train',  i)\n","        h_train_data, h_train_olabel = load_random_subject(length, 'holding', 'train', i)\n","        half_s_train_data, half_s_train_olabel, half_h_train_data, half_h_train_olabel = random_select(s_train_data, s_train_olabel, h_train_data, h_train_olabel)\n","        t_train_data = np.concatenate((half_s_train_data, half_h_train_data))\n","        t_train_olabel = np.concatenate((half_s_train_olabel, half_h_train_olabel))\n","        h_test_data, h_test_olabel = load_random_subject(length, 'holding', 'test', i)\n","        print('Now, start the cv: ',i)\n","        model = cnn_1d(input_shape = input_shape, learning_rate = 1e-3)\n","        history = model.fit(t_train_data,t_train_olabel,epochs = 25, batch_size = 32,verbose = 0, shuffle = True,\n","                            validation_data = (h_test_data, h_test_olabel))\n","        h_pred = np.argmax(model.predict(h_test_data), axis = 1)\n","        h_real_label = onehot_to_label(h_test_olabel)\n","        h_scores = accuracy_score(h_real_label, h_pred) * 100\n","        print('The accuracy in this fold (test holding): %f'%h_scores)\n","        print(\"=============================\")\n","        h_cvscores.append(h_scores)\n","        h_conf_mat = np.expand_dims(confusion_matrix(h_real_label, h_pred), axis = 2)\n","        h_conf_mat_all = np.concatenate([h_conf_mat_all, h_conf_mat], axis = 2)\n","#--------------------------------------------------------------------------------\n","# this part is to plot acc, loss curve and print out the average accuracy\n","#-------------------------------------------------------------------------------- \n","        # plot_acc(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/acc and loss/' + '1D_CNN' + '_' + length + '_inter subject (combine test holding).png')\n","        # plt.show()\n","        # plot_loss(history)\n","        # plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/acc and loss/' + '1D_CNN' + '_' + length + '_inter subject (combine test holding) loss.png')\n","        # plt.show()\n","    print('Test : holding')\n","    print(length + \" Total Accuracy (average): \", np.mean(h_cvscores), np.std(h_cvscores))\n","    print(\"=============================================\")\n","    print(\"=============================================\")\n","#--------------------------------------------------------------------------------\n","# this part is to plot confusion matrix\n","#--------------------------------------------------------------------------------\n","h_conf_mat_sum = np.sum(h_conf_mat_all, axis = 2)\n","plot_confusion_matrix(h_conf_mat_sum, classes = gestures, cmap = plt.cm.Blues,\n","                  normalize = True)\n","# plt.savefig('/home/motionlab/Desktop/weitai/final_code/碩論final/1D_CNN/confusion matrix/' + '1D_CNN' + ' combine_half_test_holding ' + ' inter_subject confusion_matrix.png')\n","plt.show()"],"execution_count":null,"outputs":[]}]}